{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marky115/Week3-Machine_Learning/blob/newBranch/Week_3_MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywb8NifF9XN3",
        "outputId": "f1316ac4-ed15-4f0b-b9f1-bd28075b7a14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5CvOjjrL9gw"
      },
      "source": [
        "<center><h1> Introduction to Audio Classification with Machine Learning Models </h1></center>\n",
        "\n",
        "\n",
        "\n",
        "### Purpose\n",
        "This notebook serves as an introduction to working with audio data for classification problems; it is meant as a learning resource rather than a demonstration of the state-of-the-art. The techniques mentioned in this notebook apply not only to classification problems, but to regression problems and problems dealing with other types of input data as well. I provide an introduction to a few key machine learning models and the logic in choosing their hyperparameters. These objectives are framed by the task of recognizing emotion from snippets of speech audio.\n",
        "\n",
        " Training data should be used strictly for training a model, validation data strictly for tuning a model, and test data strictly to evaluate a model once it is tuned - a model should never be tuned to perform better on test data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Classic machine learning models such as Support Vector Machines (SVM), k Nearest Neighbours (kNN), and Random Forests have distinct advantages to deep neural networks in many tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQsTfGREL9g1"
      },
      "source": [
        "<!--TABLE OF CONTENTS-->\n",
        "\n",
        "\n",
        "# Table of Contents\n",
        "  - [Intro: Speech Emotion Recognition on the RAVDESS dataset](#Intro:-Speech-Emotion-Recognition-on-the-RAVDESS-dataset)\n",
        "  - [Machine Learning Process Overview](#Machine-Learning-Process-Overview)\n",
        "  - [Feature Extraction](#Feature-Extraction)\n",
        "    - [Load the Dataset and Compute Features](#Load-the-Dataset-and-Compute-Features)\n",
        "    - [Feature Scaling](#Feature-Scaling)\n",
        "  - [Classical Machine Learning Models](#Classical-Machine-Learning-Models)\n",
        "    - [Training: The 80/20 Split and Validation](#Training:-The-80/20-Split-and-Validation)\n",
        "    - [Comparing Models](#Comparing-Models)\n",
        "    - [The Support Vector Machine Classifier](#The-Support-Vector-Machine-Classifier)\n",
        "    - [k Nearest Neighbours](#k-Nearest-Neighbours)\n",
        "    - [Random Forests](#Random-Forests)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hZUcbr4PL9g2"
      },
      "source": [
        "## Intro: Speech Emotion Recognition on the RAVDESS dataset\n",
        "In this notebook we explore the most common machine learning models, specifically those available off the shelf in scikit-learn.\n",
        "\n",
        "I'm going to use the RAVDESS dataset (Ryerson Audio-Visual Database of Emotional Speech and Song dataset), created by Steven Livingstone and Frank Russo of Ryerson University. <br>\n",
        "[Details of the RAVDESS dataset](https://smartlaboratory.org/ravdess/) <br>\n",
        "[Download the dataset used in this notebook](https://zenodo.org/record/1188976) <br> Scroll half-way down the page and find \"Audio_Speech_Actors_01-24\"<br>\n",
        "\n",
        "We're going to use the audio-only speech portion of the RAVDESS dataset, ~200MB.\n",
        "Audio is sourced from 24 actors (12 male, 12 female) repeating two sentences with\n",
        "a variety of emotions and intensity. We get 1440 speech files (24 actors * 60 recordings per actor). Each audio sample has been rated  by a human 10 times for emotional quality.\n",
        "\n",
        "## Machine Learning Process Overview\n",
        "1. Feature Engineering: Choose and define the properties which our model will use to evaluate the audio files. <br>\n",
        "2. Feature Extraction: Compute the features for each audio file and build a feature matrix representing all audio files. <br>\n",
        "3. Model exploration: Test candidate models that make sense for the properies of the dataset\n",
        "4. Training the MLP Classifier model: Choose and optimize the properties of our model on validation data - hyperparameters and architechture.  <br>\n",
        "5. Evaluate our model's performance: Evaluate our model's accuracy on validation data and score it against test data which it has never seen in training.<br>\n",
        "6. Explore options for improving our model: Is our dataset the right size? Is our model too complex or too simple? <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import soundfile\n",
        "import os\n",
        "# matplotlib complains about the behaviour of librosa.display, so we'll ignore those warnings:\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "b2IL0uT19_3A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=pd.read_excel('/content/drive/MyDrive/IAT481/emotionsRavdess.xlsx',index_col=0)\n",
        "emotions=pd.read_excel('/content/drive/MyDrive/IAT481/featuresRavdess.xlsx',index_col=0)"
      ],
      "metadata": {
        "id": "O7HAfWqKKaZS"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.to_excel('/content/drive/MyDrive/EmoDB/Week3/featuresEmo.xlsx')\n",
        "emotions_df.to_excel('/content/drive/MyDrive/EmoDB/Week3/emotionsEmo.xlsx')\n"
      ],
      "metadata": {
        "id": "AgbSjGjKOsgw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eu8VPhDmL9hC"
      },
      "source": [
        "## Feature Extraction\n",
        "We're going to take full advantage of librosa, a Python library enabling audio analysis and feature extraction.\n",
        "Librosa abstracts away all the math and most of the details of mel spectrorgams, chromagrams, and MFCC.\n",
        "Although closely related, we're going to take the Mel Spectrogram, MFCC, and chromagrams of each audio file as separate features to try\n",
        "and have bit more discriminatory power between samples. <br>\n",
        "\n",
        "Let's build our feature extraction functions to get a chromagram, a mel spectorgram, and MFC coefficients for each of our audio files. Because the chromagram, mel spectrogram and MFCCs are calculated on audio frames produced by STFT, we're going to get a matrix back from each function, so we'll take the mean of those matrices to produce a single feature array for each feature and each audio sample, i.e. 3 feature arrays per audio sample.\n",
        "\n",
        "**Chromagram**: Will produce 12 features; One for each of 12 pitch classes\n",
        "\n",
        "**Mel Spectrogram**: Will produce 128 features; We've defined the number of mel frequency bands at n_mels=128\n",
        "\n",
        "**MFCC**: Will produce 40 MFCCs; I've set the number of coefficients to return at n_mfcc=40 which I found to work well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qTe93WYTL9hD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def feature_chromagram(waveform, sample_rate):\n",
        "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
        "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
        "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate).T,axis=0)\n",
        "    return chromagram\n",
        "\n",
        "def feature_melspectrogram(waveform, sample_rate):\n",
        "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
        "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=8000).T,axis=0)\n",
        "    return melspectrogram\n",
        "\n",
        "def feature_mfcc(waveform, sample_rate):\n",
        "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # 40 filterbanks = 40 coefficients\n",
        "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    return mfc_coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xjFXIfC2L9hD"
      },
      "source": [
        "We're going to wrap our feature extraction functions so we only have to load each audio file once. After extracting our 3 audio features as NumPy arrays representing a time series, we're going to\n",
        "stack them horizontally to create a single feature array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xPMw9ijJL9hE"
      },
      "outputs": [],
      "source": [
        "def get_features(file):\n",
        "    # load an individual soundfile\n",
        "     with soundfile.SoundFile(file) as audio:\n",
        "        waveform = audio.read(dtype=\"float32\")\n",
        "        sample_rate = audio.samplerate\n",
        "        # compute features of soundfile\n",
        "        chromagram = feature_chromagram(waveform, sample_rate)\n",
        "        melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
        "        mfc_coefficients = feature_mfcc(waveform, sample_rate)\n",
        "\n",
        "        feature_matrix=np.array([])\n",
        "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
        "        feature_matrix = np.hstack((chromagram, melspectrogram, mfc_coefficients))\n",
        "\n",
        "        return feature_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "c-C6g6psL9hE"
      },
      "source": [
        "### Load the Dataset and Compute Features\n",
        "We have to understand the labelling of the RAVDESS dataset to find the ground truth emotion for each sample.\n",
        "Each file is labelled with 7 numbers delimited by a \"-\".\n",
        "Most of the numbers describe metadata about the audio samples such as their format (video and/or audio),\n",
        "whether the audio is a song or statement, which of two statements is being read and by which actor.\n",
        "\n",
        "The third and fourth numbers pertain to the emotional quality of each sample. The third number is in the range of 1-8 with each number representing an emotion.\n",
        "The fourth number is either 1 or 2, representing normal (1) or strong (2) emotional intensity.\n",
        "\n",
        "We're going to define a dictionary based on the third number (emotion) and assign an emotion to each number as specified by the RAVDESS dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z-Pu_fB7L9hF"
      },
      "outputs": [],
      "source": [
        "#Emotions in the RAVDESS dataset\n",
        "emotions ={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "\n",
        "emodb_emotions = {\n",
        "    'N':'neutral',\n",
        "    'L':'calm',\n",
        "    'F':'happy',\n",
        "    'T':'sad',\n",
        "    'W':'angry',\n",
        "    'A':'fearful',\n",
        "    'E':'disgust'\n",
        "}\n",
        "\n",
        "emodb_actors = {\n",
        "    '03':'25',\n",
        "    '08':'26',\n",
        "    '10':'27',\n",
        "    '09':'28',\n",
        "    '11':'29',\n",
        "    '13':'30',\n",
        "    '12':'31',\n",
        "    '14':'32',\n",
        "    '15':'33',\n",
        "    '16':'34'\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pTlsUOwXL9hF"
      },
      "source": [
        "Finally, let's load our entire dataset and compute the features of each audio file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mAh2AYMpL9hF"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "\n",
        "    for file in glob.glob(\"/content/drive/MyDrive/Audio_Speech_Actors_01-24/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        print(file_name)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        features = get_features(file)\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data_Emo():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "\n",
        "    for file in glob.glob(\"/content/drive/MyDrive/EmoDB/wav/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        print(file_name)\n",
        "        emotionsEmo=emodb_emotions[file_name[5]]\n",
        "        featuresEmo = get_features(file)\n",
        "        X.append(featuresEmo)\n",
        "        y.append(emotionsEmo)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "ub98Wz0KLlmL"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3Cf8q4K5L9hG"
      },
      "source": [
        "Compute the feature matrix and read the emotion labels for the entire dataset.\n",
        "Note that our regressor (independent/explanatory variable), usually denoted X, is named 'features', and our regressand (dependent variable), usually denoted y, is named 'emotions'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XeKE591aL9hG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "0f0fef2e-6f8b-41ca-8861-4b42cb6f635d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03-01-07-02-02-02-17.wav\n",
            "\r Processed 1/1440 audio samples 03-01-06-02-02-01-17.wav\n",
            " Processed 2/1440 audio samples 03-01-07-01-02-02-17.wav\n",
            " Processed 3/1440 audio samples 03-01-07-01-01-02-17.wav\n",
            " Processed 4/1440 audio samples 03-01-08-01-01-02-17.wav\n",
            " Processed 5/1440 audio samples 03-01-06-02-01-02-17.wav\n",
            " Processed 6/1440 audio samples 03-01-08-02-01-02-17.wav\n",
            " Processed 7/1440 audio samples 03-01-08-02-02-01-17.wav\n",
            " Processed 8/1440 audio samples 03-01-07-02-02-01-17.wav\n",
            " Processed 9/1440 audio samples 03-01-06-02-02-02-17.wav\n",
            " Processed 10/1440 audio samples 03-01-04-01-01-02-17.wav\n",
            " Processed 11/1440 audio samples 03-01-08-01-01-01-17.wav\n",
            " Processed 12/1440 audio samples 03-01-06-02-01-01-17.wav\n",
            " Processed 13/1440 audio samples 03-01-07-01-02-01-17.wav\n",
            " Processed 14/1440 audio samples 03-01-08-01-02-02-17.wav\n",
            " Processed 15/1440 audio samples 03-01-08-02-02-02-17.wav\n",
            " Processed 16/1440 audio samples 03-01-06-01-02-02-17.wav\n",
            " Processed 17/1440 audio samples 03-01-05-02-01-02-17.wav\n",
            " Processed 18/1440 audio samples 03-01-06-01-02-01-17.wav\n",
            " Processed 19/1440 audio samples 03-01-08-02-01-01-17.wav\n",
            " Processed 20/1440 audio samples 03-01-07-01-01-01-17.wav\n",
            " Processed 21/1440 audio samples 03-01-08-01-02-01-17.wav\n",
            " Processed 22/1440 audio samples 03-01-06-01-01-02-17.wav\n",
            " Processed 23/1440 audio samples 03-01-07-02-01-01-17.wav\n",
            " Processed 24/1440 audio samples 03-01-04-02-02-01-17.wav\n",
            " Processed 25/1440 audio samples 03-01-03-02-02-02-17.wav\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-cff2071d310c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-86-de7cd5e787eb>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-acfeb0d70b30>\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mchromagram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_chromagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmelspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_melspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmfc_coefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-6c7fe42b11ae>\u001b[0m in \u001b[0;36mfeature_mfcc\u001b[0;34m(waveform, sample_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 40 filterbanks = 40 coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmfc_coefficients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmfc_coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m     M: np.ndarray = scipy.fftpack.dct(S, axis=-2, type=dct_type, norm=norm)[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[0;31m# Build a Mel filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     \u001b[0mmelspec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"...ft,mf->...mt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/filters.py\u001b[0m in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# .. then intersect them with each other and zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "features, emotions = load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "featuresEmo, emotionsEmo = load_data_Emo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIXyrQS-MSqj",
        "outputId": "47f3a327-d625-4291-a0d9-cd24284cc51e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03a02Nc.wav\n",
            " Processed 1/1440 audio samples 03a02Wb.wav\n",
            " Processed 2/1440 audio samples 03a02Fc.wav\n",
            " Processed 3/1440 audio samples 03a01Wa.wav\n",
            " Processed 4/1440 audio samples 03a02Ta.wav\n",
            " Processed 5/1440 audio samples 03a01Nc.wav\n",
            " Processed 6/1440 audio samples 03a01Fa.wav\n",
            " Processed 7/1440 audio samples 11a02Fb.wav\n",
            " Processed 8/1440 audio samples 08b01Aa.wav\n",
            " Processed 9/1440 audio samples 08a05Ta.wav\n",
            " Processed 10/1440 audio samples 09a05Ed.wav\n",
            " Processed 11/1440 audio samples 03a02Wc.wav\n",
            " Processed 12/1440 audio samples 09a02Ea.wav\n",
            " Processed 13/1440 audio samples 03b09La.wav\n",
            " Processed 14/1440 audio samples 08b10Tc.wav\n",
            " Processed 15/1440 audio samples 11a05Ad.wav\n",
            " Processed 16/1440 audio samples 10b02Aa.wav\n",
            " Processed 17/1440 audio samples 09a02Eb.wav\n",
            " Processed 18/1440 audio samples 08a05Fe.wav\n",
            " Processed 19/1440 audio samples 09a05Lc.wav\n",
            " Processed 20/1440 audio samples 09b02Tb.wav\n",
            " Processed 21/1440 audio samples 08b09Fd.wav\n",
            " Processed 22/1440 audio samples 09b10Aa.wav\n",
            " Processed 23/1440 audio samples 09a04Fd.wav\n",
            " Processed 24/1440 audio samples 10a01Ac.wav\n",
            " Processed 25/1440 audio samples 09a07Eb.wav\n",
            " Processed 26/1440 audio samples 03b10Ec.wav\n",
            " Processed 27/1440 audio samples 03a05Wa.wav\n",
            " Processed 28/1440 audio samples 11a05Fb.wav\n",
            " Processed 29/1440 audio samples 08b09Nb.wav\n",
            " Processed 30/1440 audio samples 03b01Lb.wav\n",
            " Processed 31/1440 audio samples 09b10Wa.wav\n",
            " Processed 32/1440 audio samples 03b01Fa.wav\n",
            " Processed 33/1440 audio samples 10a07Wb.wav\n",
            " Processed 34/1440 audio samples 08b09Lc.wav\n",
            " Processed 35/1440 audio samples 10a04Fd.wav\n",
            " Processed 36/1440 audio samples 10b10Fc.wav\n",
            " Processed 37/1440 audio samples 08a07Wc.wav\n",
            " Processed 38/1440 audio samples 03b02Na.wav\n",
            " Processed 39/1440 audio samples 03b01Wc.wav\n",
            " Processed 40/1440 audio samples 09a04La.wav\n",
            " Processed 41/1440 audio samples 08a01Ab.wav\n",
            " Processed 42/1440 audio samples 03b03Nb.wav\n",
            " Processed 43/1440 audio samples 03b03Wc.wav\n",
            " Processed 44/1440 audio samples 10a07Aa.wav\n",
            " Processed 45/1440 audio samples 08a02Ac.wav\n",
            " Processed 46/1440 audio samples 03a07Fa.wav\n",
            " Processed 47/1440 audio samples 10b09Lb.wav\n",
            " Processed 48/1440 audio samples 08a02La.wav\n",
            " Processed 49/1440 audio samples 03b02Aa.wav\n",
            " Processed 50/1440 audio samples 10b01Aa.wav\n",
            " Processed 51/1440 audio samples 10a07Ad.wav\n",
            " Processed 52/1440 audio samples 10a05Tb.wav\n",
            " Processed 53/1440 audio samples 08b01Wa.wav\n",
            " Processed 54/1440 audio samples 03b10Na.wav\n",
            " Processed 55/1440 audio samples 10b02La.wav\n",
            " Processed 56/1440 audio samples 08b09Wc.wav\n",
            " Processed 57/1440 audio samples 09a05Nb.wav\n",
            " Processed 58/1440 audio samples 03a05Aa.wav\n",
            " Processed 59/1440 audio samples 10a05Wb.wav\n",
            " Processed 60/1440 audio samples 11a02Tc.wav\n",
            " Processed 61/1440 audio samples 11a02Nc.wav\n",
            " Processed 62/1440 audio samples 09a05Wc.wav\n",
            " Processed 63/1440 audio samples 08a04Wc.wav\n",
            " Processed 64/1440 audio samples 03b01Wa.wav\n",
            " Processed 65/1440 audio samples 09a07Wd.wav\n",
            " Processed 66/1440 audio samples 03b02Wb.wav\n",
            " Processed 67/1440 audio samples 08a02Na.wav\n",
            " Processed 68/1440 audio samples 08b03Lc.wav\n",
            " Processed 69/1440 audio samples 09a07Ta.wav\n",
            " Processed 70/1440 audio samples 10a05Ld.wav\n",
            " Processed 71/1440 audio samples 08b01Lb.wav\n",
            " Processed 72/1440 audio samples 03b10Nc.wav\n",
            " Processed 73/1440 audio samples 09a07Na.wav\n",
            " Processed 74/1440 audio samples 03a05Nd.wav\n",
            " Processed 75/1440 audio samples 09b03Ed.wav\n",
            " Processed 76/1440 audio samples 08a01Fd.wav\n",
            " Processed 77/1440 audio samples 11a01Nd.wav\n",
            " Processed 78/1440 audio samples 09a04Wa.wav\n",
            " Processed 79/1440 audio samples 11a04Wc.wav\n",
            " Processed 80/1440 audio samples 10a05Aa.wav\n",
            " Processed 81/1440 audio samples 08a07La.wav\n",
            " Processed 82/1440 audio samples 08a02Ab.wav\n",
            " Processed 83/1440 audio samples 09b03Ta.wav\n",
            " Processed 84/1440 audio samples 09b09Nd.wav\n",
            " Processed 85/1440 audio samples 09b09Ea.wav\n",
            " Processed 86/1440 audio samples 08b03Tc.wav\n",
            " Processed 87/1440 audio samples 03a04Fd.wav\n",
            " Processed 88/1440 audio samples 09a01Fa.wav\n",
            " Processed 89/1440 audio samples 08b10La.wav\n",
            " Processed 90/1440 audio samples 08b02Ff.wav\n",
            " Processed 91/1440 audio samples 08a05Wa.wav\n",
            " Processed 92/1440 audio samples 09a05Wb.wav\n",
            " Processed 93/1440 audio samples 08b10Aa.wav\n",
            " Processed 94/1440 audio samples 08b10Fd.wav\n",
            " Processed 95/1440 audio samples 10b02Wb.wav\n",
            " Processed 96/1440 audio samples 08b02Wd.wav\n",
            " Processed 97/1440 audio samples 10b01Fa.wav\n",
            " Processed 98/1440 audio samples 11a01Ab.wav\n",
            " Processed 99/1440 audio samples 09a01Ea.wav\n",
            " Processed 100/1440 audio samples 08a01Na.wav\n",
            " Processed 101/1440 audio samples 11a02Ld.wav\n",
            " Processed 102/1440 audio samples 08b03Nb.wav\n",
            " Processed 103/1440 audio samples 10b03La.wav\n",
            " Processed 104/1440 audio samples 09a04Nb.wav\n",
            " Processed 105/1440 audio samples 08b01Fe.wav\n",
            " Processed 106/1440 audio samples 09a02La.wav\n",
            " Processed 107/1440 audio samples 09b10Nd.wav\n",
            " Processed 108/1440 audio samples 03a07Fb.wav\n",
            " Processed 109/1440 audio samples 03b02Tb.wav\n",
            " Processed 110/1440 audio samples 03b01Nb.wav\n",
            " Processed 111/1440 audio samples 11a02Wc.wav\n",
            " Processed 112/1440 audio samples 10a02Na.wav\n",
            " Processed 113/1440 audio samples 09a07Wb.wav\n",
            " Processed 114/1440 audio samples 08a01Wc.wav\n",
            " Processed 115/1440 audio samples 11a01Ld.wav\n",
            " Processed 116/1440 audio samples 08b10Nc.wav\n",
            " Processed 117/1440 audio samples 10b03Wb.wav\n",
            " Processed 118/1440 audio samples 10a01Nb.wav\n",
            " Processed 119/1440 audio samples 09b02Wd.wav\n",
            " Processed 120/1440 audio samples 09a02Wb.wav\n",
            " Processed 121/1440 audio samples 10b10Lc.wav\n",
            " Processed 122/1440 audio samples 10a04Nb.wav\n",
            " Processed 123/1440 audio samples 11a01Wc.wav\n",
            " Processed 124/1440 audio samples 10a01Wa.wav\n",
            " Processed 125/1440 audio samples 09a05Tb.wav\n",
            " Processed 126/1440 audio samples 03a04Nc.wav\n",
            " Processed 127/1440 audio samples 08b01Fd.wav\n",
            " Processed 128/1440 audio samples 09b09Wa.wav\n",
            " Processed 129/1440 audio samples 03b09Tc.wav\n",
            " Processed 130/1440 audio samples 08a05Lc.wav\n",
            " Processed 131/1440 audio samples 09b01Wb.wav\n",
            " Processed 132/1440 audio samples 03a05Fc.wav\n",
            " Processed 133/1440 audio samples 03b10Wb.wav\n",
            " Processed 134/1440 audio samples 09b02Na.wav\n",
            " Processed 135/1440 audio samples 10a07Ta.wav\n",
            " Processed 136/1440 audio samples 03a05Wb.wav\n",
            " Processed 137/1440 audio samples 08b01Na.wav\n",
            " Processed 138/1440 audio samples 03b03Tc.wav\n",
            " Processed 139/1440 audio samples 09b01Na.wav\n",
            " Processed 140/1440 audio samples 08a07Fd.wav\n",
            " Processed 141/1440 audio samples 03b09Nc.wav\n",
            " Processed 142/1440 audio samples 08a04La.wav\n",
            " Processed 143/1440 audio samples 08b02Nb.wav\n",
            " Processed 144/1440 audio samples 03a07Nc.wav\n",
            " Processed 145/1440 audio samples 08b09Tb.wav\n",
            " Processed 146/1440 audio samples 10b01Ea.wav\n",
            " Processed 147/1440 audio samples 08a01Wa.wav\n",
            " Processed 148/1440 audio samples 08a07Na.wav\n",
            " Processed 149/1440 audio samples 08b03Fe.wav\n",
            " Processed 150/1440 audio samples 08a07Ta.wav\n",
            " Processed 151/1440 audio samples 09b03Lb.wav\n",
            " Processed 152/1440 audio samples 03b10Wc.wav\n",
            " Processed 153/1440 audio samples 11a05Lc.wav\n",
            " Processed 154/1440 audio samples 08b09Ab.wav\n",
            " Processed 155/1440 audio samples 09b03Fd.wav\n",
            " Processed 156/1440 audio samples 10a04Wb.wav\n",
            " Processed 157/1440 audio samples 10b10Wa.wav\n",
            " Processed 158/1440 audio samples 03a04Wc.wav\n",
            " Processed 159/1440 audio samples 08b03Wd.wav\n",
            " Processed 160/1440 audio samples 10a04Wa.wav\n",
            " Processed 161/1440 audio samples 09b03Fa.wav\n",
            " Processed 162/1440 audio samples 08a07Tb.wav\n",
            " Processed 163/1440 audio samples 08a02Tb.wav\n",
            " Processed 164/1440 audio samples 08a02Wc.wav\n",
            " Processed 165/1440 audio samples 08a04Nc.wav\n",
            " Processed 166/1440 audio samples 03a04Lc.wav\n",
            " Processed 167/1440 audio samples 09b03Nb.wav\n",
            " Processed 168/1440 audio samples 10b03Tb.wav\n",
            " Processed 169/1440 audio samples 03b02La.wav\n",
            " Processed 170/1440 audio samples 11a04Nd.wav\n",
            " Processed 171/1440 audio samples 10a07La.wav\n",
            " Processed 172/1440 audio samples 09b01Ea.wav\n",
            " Processed 173/1440 audio samples 10b09Ad.wav\n",
            " Processed 174/1440 audio samples 11a04Fd.wav\n",
            " Processed 175/1440 audio samples 10b09Wb.wav\n",
            " Processed 176/1440 audio samples 03a04Ad.wav\n",
            " Processed 177/1440 audio samples 08a01Lc.wav\n",
            " Processed 178/1440 audio samples 10a02Ab.wav\n",
            " Processed 179/1440 audio samples 08b02La.wav\n",
            " Processed 180/1440 audio samples 08a05Nb.wav\n",
            " Processed 181/1440 audio samples 03a07La.wav\n",
            " Processed 182/1440 audio samples 03b10Ab.wav\n",
            " Processed 183/1440 audio samples 08b02Tc.wav\n",
            " Processed 184/1440 audio samples 08a02Fe.wav\n",
            " Processed 185/1440 audio samples 11a02Ec.wav\n",
            " Processed 186/1440 audio samples 10a02Wa.wav\n",
            " Processed 187/1440 audio samples 09b02Wc.wav\n",
            " Processed 188/1440 audio samples 10a02Fa.wav\n",
            " Processed 189/1440 audio samples 08b09Wa.wav\n",
            " Processed 190/1440 audio samples 09a01Nb.wav\n",
            " Processed 191/1440 audio samples 03b01Td.wav\n",
            " Processed 192/1440 audio samples 09a01Wb.wav\n",
            " Processed 193/1440 audio samples 08b10Wa.wav\n",
            " Processed 194/1440 audio samples 09b03Wb.wav\n",
            " Processed 195/1440 audio samples 10b01Lb.wav\n",
            " Processed 196/1440 audio samples 03a05Tc.wav\n",
            " Processed 197/1440 audio samples 08a04Ff.wav\n",
            " Processed 198/1440 audio samples 10b02Na.wav\n",
            " Processed 199/1440 audio samples 11a04Ac.wav\n",
            " Processed 200/1440 audio samples 03b09Wa.wav\n",
            " Processed 201/1440 audio samples 08a04Tb.wav\n",
            " Processed 202/1440 audio samples 11a01Aa.wav\n",
            " Processed 203/1440 audio samples 11a05Fc.wav\n",
            " Processed 204/1440 audio samples 03a04Ta.wav\n",
            " Processed 205/1440 audio samples 10a02Lb.wav\n",
            " Processed 206/1440 audio samples 03a07Wc.wav\n",
            " Processed 207/1440 audio samples 11b03Nb.wav\n",
            " Processed 208/1440 audio samples 14b01Ac.wav\n",
            " Processed 209/1440 audio samples 11b09Fd.wav\n",
            " Processed 210/1440 audio samples 14b09Ac.wav\n",
            " Processed 211/1440 audio samples 12b02Na.wav\n",
            " Processed 212/1440 audio samples 11a05Na.wav\n",
            " Processed 213/1440 audio samples 12b03Ta.wav\n",
            " Processed 214/1440 audio samples 11a07Ta.wav\n",
            " Processed 215/1440 audio samples 12b09Wc.wav\n",
            " Processed 216/1440 audio samples 12b10Ac.wav\n",
            " Processed 217/1440 audio samples 14a01Na.wav\n",
            " Processed 218/1440 audio samples 13a05Tc.wav\n",
            " Processed 219/1440 audio samples 14a04Wc.wav\n",
            " Processed 220/1440 audio samples 12a02Ec.wav\n",
            " Processed 221/1440 audio samples 14b01Fc.wav\n",
            " Processed 222/1440 audio samples 14b03Ed.wav\n",
            " Processed 223/1440 audio samples 14a04Ed.wav\n",
            " Processed 224/1440 audio samples 13b01Ld.wav\n",
            " Processed 225/1440 audio samples 13b10Wa.wav\n",
            " Processed 226/1440 audio samples 11b09Wa.wav\n",
            " Processed 227/1440 audio samples 13b01Ec.wav\n",
            " Processed 228/1440 audio samples 14a07Eb.wav\n",
            " Processed 229/1440 audio samples 13a07Na.wav\n",
            " Processed 230/1440 audio samples 13b09Wa.wav\n",
            " Processed 231/1440 audio samples 13a02Ad.wav\n",
            " Processed 232/1440 audio samples 11b09Ad.wav\n",
            " Processed 233/1440 audio samples 11b03Wb.wav\n",
            " Processed 234/1440 audio samples 11b01Ab.wav\n",
            " Processed 235/1440 audio samples 12a01Wc.wav\n",
            " Processed 236/1440 audio samples 12b02Fb.wav\n",
            " Processed 237/1440 audio samples 13a05Lc.wav\n",
            " Processed 238/1440 audio samples 12b02Wb.wav\n",
            " Processed 239/1440 audio samples 14a02Wc.wav\n",
            " Processed 240/1440 audio samples 12b03La.wav\n",
            " Processed 241/1440 audio samples 13a07Fd.wav\n",
            " Processed 242/1440 audio samples 14a07Wc.wav\n",
            " Processed 243/1440 audio samples 12a02Wa.wav\n",
            " Processed 244/1440 audio samples 13b03Td.wav\n",
            " Processed 245/1440 audio samples 12b02Ea.wav\n",
            " Processed 246/1440 audio samples 13b02Nb.wav\n",
            " Processed 247/1440 audio samples 13a02Wa.wav\n",
            " Processed 248/1440 audio samples 14a01Ea.wav\n",
            " Processed 249/1440 audio samples 11b10Ae.wav\n",
            " Processed 250/1440 audio samples 12a04Wc.wav\n",
            " Processed 251/1440 audio samples 13a04Wc.wav\n",
            " Processed 252/1440 audio samples 14b02Wb.wav\n",
            " Processed 253/1440 audio samples 14a02Nc.wav\n",
            " Processed 254/1440 audio samples 13b03Wc.wav\n",
            " Processed 255/1440 audio samples 13a05Nb.wav\n",
            " Processed 256/1440 audio samples 13b10Fa.wav\n",
            " Processed 257/1440 audio samples 11a07Wc.wav\n",
            " Processed 258/1440 audio samples 14a05Ac.wav\n",
            " Processed 259/1440 audio samples 12a02Nb.wav\n",
            " Processed 260/1440 audio samples 14a05Aa.wav\n",
            " Processed 261/1440 audio samples 14a02Fd.wav\n",
            " Processed 262/1440 audio samples 12a01Nb.wav\n",
            " Processed 263/1440 audio samples 13b10Wc.wav\n",
            " Processed 264/1440 audio samples 13b09La.wav\n",
            " Processed 265/1440 audio samples 13a01Lb.wav\n",
            " Processed 266/1440 audio samples 14b03Ad.wav\n",
            " Processed 267/1440 audio samples 12b10Ld.wav\n",
            " Processed 268/1440 audio samples 13b09Ab.wav\n",
            " Processed 269/1440 audio samples 13a04Fc.wav\n",
            " Processed 270/1440 audio samples 11b03Lc.wav\n",
            " Processed 271/1440 audio samples 12b10Wa.wav\n",
            " Processed 272/1440 audio samples 11a05Td.wav\n",
            " Processed 273/1440 audio samples 13a05Aa.wav\n",
            " Processed 274/1440 audio samples 14a04Wb.wav\n",
            " Processed 275/1440 audio samples 14a05Ta.wav\n",
            " Processed 276/1440 audio samples 14a07Lc.wav\n",
            " Processed 277/1440 audio samples 13b03Ac.wav\n",
            " Processed 278/1440 audio samples 11b01Nc.wav\n",
            " Processed 279/1440 audio samples 14b01Eb.wav\n",
            " Processed 280/1440 audio samples 14a05Tc.wav\n",
            " Processed 281/1440 audio samples 13a05Wa.wav\n",
            " Processed 282/1440 audio samples 13b01Wa.wav\n",
            " Processed 283/1440 audio samples 13a01Ac.wav\n",
            " Processed 284/1440 audio samples 14a07Na.wav\n",
            " Processed 285/1440 audio samples 13a07Wb.wav\n",
            " Processed 286/1440 audio samples 14b09Ea.wav\n",
            " Processed 287/1440 audio samples 13b02Fb.wav\n",
            " Processed 288/1440 audio samples 12a01Fb.wav\n",
            " Processed 289/1440 audio samples 14b03Ta.wav\n",
            " Processed 290/1440 audio samples 12b02Wd.wav\n",
            " Processed 291/1440 audio samples 13a01Nb.wav\n",
            " Processed 292/1440 audio samples 13b10Ec.wav\n",
            " Processed 293/1440 audio samples 12a02Wc.wav\n",
            " Processed 294/1440 audio samples 13a02Nc.wav\n",
            " Processed 295/1440 audio samples 13a01Fd.wav\n",
            " Processed 296/1440 audio samples 13a01Wb.wav\n",
            " Processed 297/1440 audio samples 13b02Wa.wav\n",
            " Processed 298/1440 audio samples 12a07Ac.wav\n",
            " Processed 299/1440 audio samples 14a02Ea.wav\n",
            " Processed 300/1440 audio samples 13b09Na.wav\n",
            " Processed 301/1440 audio samples 14b02Tc.wav\n",
            " Processed 302/1440 audio samples 13b09Fc.wav\n",
            " Processed 303/1440 audio samples 12b01Ta.wav\n",
            " Processed 304/1440 audio samples 11a05Wd.wav\n",
            " Processed 305/1440 audio samples 11b10Ad.wav\n",
            " Processed 306/1440 audio samples 14a05Wa.wav\n",
            " Processed 307/1440 audio samples 13a01Ea.wav\n",
            " Processed 308/1440 audio samples 12b02Wa.wav\n",
            " Processed 309/1440 audio samples 13a02Lc.wav\n",
            " Processed 310/1440 audio samples 11b10Td.wav\n",
            " Processed 311/1440 audio samples 14a07Ld.wav\n",
            " Processed 312/1440 audio samples 13b03Ed.wav\n",
            " Processed 313/1440 audio samples 14a02Wa.wav\n",
            " Processed 314/1440 audio samples 13b10La.wav\n",
            " Processed 315/1440 audio samples 14a01Wa.wav\n",
            " Processed 316/1440 audio samples 13b03Na.wav\n",
            " Processed 317/1440 audio samples 12a05Nd.wav\n",
            " Processed 318/1440 audio samples 13a05Wc.wav\n",
            " Processed 319/1440 audio samples 14a02Tb.wav\n",
            " Processed 320/1440 audio samples 11b01Eb.wav\n",
            " Processed 321/1440 audio samples 11a07Ac.wav\n",
            " Processed 322/1440 audio samples 13a07Lb.wav\n",
            " Processed 323/1440 audio samples 11b10Ld.wav\n",
            " Processed 324/1440 audio samples 14a02La.wav\n",
            " Processed 325/1440 audio samples 14b01Wc.wav\n",
            " Processed 326/1440 audio samples 14b01Fa.wav\n",
            " Processed 327/1440 audio samples 12a02Ac.wav\n",
            " Processed 328/1440 audio samples 13b01Ab.wav\n",
            " Processed 329/1440 audio samples 11b01Lb.wav\n",
            " Processed 330/1440 audio samples 14b02Aa.wav\n",
            " Processed 331/1440 audio samples 12a05Ta.wav\n",
            " Processed 332/1440 audio samples 14b03Lb.wav\n",
            " Processed 333/1440 audio samples 14a01Ac.wav\n",
            " Processed 334/1440 audio samples 13b03Lb.wav\n",
            " Processed 335/1440 audio samples 11b02Ab.wav\n",
            " Processed 336/1440 audio samples 11b01Wd.wav\n",
            " Processed 337/1440 audio samples 13b01Fc.wav\n",
            " Processed 338/1440 audio samples 14a07Fd.wav\n",
            " Processed 339/1440 audio samples 11b09Na.wav\n",
            " Processed 340/1440 audio samples 14a05Wb.wav\n",
            " Processed 341/1440 audio samples 11b10Wa.wav\n",
            " Processed 342/1440 audio samples 14a05Na.wav\n",
            " Processed 343/1440 audio samples 11b09Td.wav\n",
            " Processed 344/1440 audio samples 14b02Wd.wav\n",
            " Processed 345/1440 audio samples 13a04Ac.wav\n",
            " Processed 346/1440 audio samples 14a07Aa.wav\n",
            " Processed 347/1440 audio samples 13a02Ec.wav\n",
            " Processed 348/1440 audio samples 13b09Fb.wav\n",
            " Processed 349/1440 audio samples 14a05Lb.wav\n",
            " Processed 350/1440 audio samples 11b10Nc.wav\n",
            " Processed 351/1440 audio samples 12a05Lb.wav\n",
            " Processed 352/1440 audio samples 12b01Wa.wav\n",
            " Processed 353/1440 audio samples 13a01Ec.wav\n",
            " Processed 354/1440 audio samples 13a07Tc.wav\n",
            " Processed 355/1440 audio samples 14a04Lb.wav\n",
            " Processed 356/1440 audio samples 13a04Ta.wav\n",
            " Processed 357/1440 audio samples 14a04Aa.wav\n",
            " Processed 358/1440 audio samples 14b01Na.wav\n",
            " Processed 359/1440 audio samples 13a04Lb.wav\n",
            " Processed 360/1440 audio samples 13b02Lc.wav\n",
            " Processed 361/1440 audio samples 14a04Tc.wav\n",
            " Processed 362/1440 audio samples 14a04Tb.wav\n",
            " Processed 363/1440 audio samples 11b02Wb.wav\n",
            " Processed 364/1440 audio samples 11b03Td.wav\n",
            " Processed 365/1440 audio samples 14a02Ab.wav\n",
            " Processed 366/1440 audio samples 11b02Fd.wav\n",
            " Processed 367/1440 audio samples 12a05Ab.wav\n",
            " Processed 368/1440 audio samples 13b10Nc.wav\n",
            " Processed 369/1440 audio samples 12a05Wb.wav\n",
            " Processed 370/1440 audio samples 14a01Aa.wav\n",
            " Processed 371/1440 audio samples 12b02Ad.wav\n",
            " Processed 372/1440 audio samples 14a05Fb.wav\n",
            " Processed 373/1440 audio samples 11b02Na.wav\n",
            " Processed 374/1440 audio samples 13a05Ea.wav\n",
            " Processed 375/1440 audio samples 14b02Fb.wav\n",
            " Processed 376/1440 audio samples 11b03Wa.wav\n",
            " Processed 377/1440 audio samples 13b09Ec.wav\n",
            " Processed 378/1440 audio samples 11b09Ld.wav\n",
            " Processed 379/1440 audio samples 13a02Ta.wav\n",
            " Processed 380/1440 audio samples 14a05Fa.wav\n",
            " Processed 381/1440 audio samples 13b01Nc.wav\n",
            " Processed 382/1440 audio samples 13b03Fd.wav\n",
            " Processed 383/1440 audio samples 12a01Lb.wav\n",
            " Processed 384/1440 audio samples 12a07La.wav\n",
            " Processed 385/1440 audio samples 14b02Na.wav\n",
            " Processed 386/1440 audio samples 13a02Fa.wav\n",
            " Processed 387/1440 audio samples 14a01Wc.wav\n",
            " Processed 388/1440 audio samples 14a07Tc.wav\n",
            " Processed 389/1440 audio samples 14b03Wb.wav\n",
            " Processed 390/1440 audio samples 12b09Td.wav\n",
            " Processed 391/1440 audio samples 12b09Ac.wav\n",
            " Processed 392/1440 audio samples 11b03Fc.wav\n",
            " Processed 393/1440 audio samples 12a07Wa.wav\n",
            " Processed 394/1440 audio samples 11b01Fc.wav\n",
            " Processed 395/1440 audio samples 11b02Td.wav\n",
            " Processed 396/1440 audio samples 11a07Ld.wav\n",
            " Processed 397/1440 audio samples 15a02Wb.wav\n",
            " Processed 398/1440 audio samples 16b01La.wav\n",
            " Processed 399/1440 audio samples 15a05Na.wav\n",
            " Processed 400/1440 audio samples 15b10Wa.wav\n",
            " Processed 401/1440 audio samples 15b02Lb.wav\n",
            " Processed 402/1440 audio samples 15a02Ac.wav\n",
            " Processed 403/1440 audio samples 16a02Nb.wav\n",
            " Processed 404/1440 audio samples 16a02Lb.wav\n",
            " Processed 405/1440 audio samples 16a07Fb.wav\n",
            " Processed 406/1440 audio samples 16a01Fc.wav\n",
            " Processed 407/1440 audio samples 15a07Ac.wav\n",
            " Processed 408/1440 audio samples 15b09La.wav\n",
            " Processed 409/1440 audio samples 16b03Wb.wav\n",
            " Processed 410/1440 audio samples 16a04Fa.wav\n",
            " Processed 411/1440 audio samples 16b03Ea.wav\n",
            " Processed 412/1440 audio samples 16a07Ea.wav\n",
            " Processed 413/1440 audio samples 15a07Eb.wav\n",
            " Processed 414/1440 audio samples 16b01Wa.wav\n",
            " Processed 415/1440 audio samples 16a07La.wav\n",
            " Processed 416/1440 audio samples 15b01Wc.wav\n",
            " Processed 417/1440 audio samples 14b10Ad.wav\n",
            " Processed 418/1440 audio samples 15b01Ec.wav\n",
            " Processed 419/1440 audio samples 15b03Wa.wav\n",
            " Processed 420/1440 audio samples 16b02Wb.wav\n",
            " Processed 421/1440 audio samples 16a02Ea.wav\n",
            " Processed 422/1440 audio samples 15a05Wa.wav\n",
            " Processed 423/1440 audio samples 16b10Wa.wav\n",
            " Processed 424/1440 audio samples 15b03Tc.wav\n",
            " Processed 425/1440 audio samples 15b10Ac.wav\n",
            " Processed 426/1440 audio samples 15a02Wd.wav\n",
            " Processed 427/1440 audio samples 15a01Nb.wav\n",
            " Processed 428/1440 audio samples 16a07Fa.wav\n",
            " Processed 429/1440 audio samples 14b09Fc.wav\n",
            " Processed 430/1440 audio samples 16b10Fb.wav\n",
            " Processed 431/1440 audio samples 16b02Eb.wav\n",
            " Processed 432/1440 audio samples 16b03Fd.wav\n",
            " Processed 433/1440 audio samples 16a01Lb.wav\n",
            " Processed 434/1440 audio samples 15b10Lc.wav\n",
            " Processed 435/1440 audio samples 15a07Nc.wav\n",
            " Processed 436/1440 audio samples 16a05Ea.wav\n",
            " Processed 437/1440 audio samples 15b09Nb.wav\n",
            " Processed 438/1440 audio samples 16b03Ta.wav\n",
            " Processed 439/1440 audio samples 14b09Wa.wav\n",
            " Processed 440/1440 audio samples 16b09Wb.wav\n",
            " Processed 441/1440 audio samples 16a01Ec.wav\n",
            " Processed 442/1440 audio samples 15a05Fb.wav\n",
            " Processed 443/1440 audio samples 16a02Tc.wav\n",
            " Processed 444/1440 audio samples 14b10Eb.wav\n",
            " Processed 445/1440 audio samples 16b09Eb.wav\n",
            " Processed 446/1440 audio samples 15b10Nb.wav\n",
            " Processed 447/1440 audio samples 15b09Ta.wav\n",
            " Processed 448/1440 audio samples 15a01Wa.wav\n",
            " Processed 449/1440 audio samples 15b09Ac.wav\n",
            " Processed 450/1440 audio samples 16b02Aa.wav\n",
            " Processed 451/1440 audio samples 16a07Nb.wav\n",
            " Processed 452/1440 audio samples 15b01Na.wav\n",
            " Processed 453/1440 audio samples 16b10Eb.wav\n",
            " Processed 454/1440 audio samples 15a07Fa.wav\n",
            " Processed 455/1440 audio samples 16a04Lc.wav\n",
            " Processed 456/1440 audio samples 15a01Fb.wav\n",
            " Processed 457/1440 audio samples 15a07Ld.wav\n",
            " Processed 458/1440 audio samples 16a04La.wav\n",
            " Processed 459/1440 audio samples 16a05Fc.wav\n",
            " Processed 460/1440 audio samples 16b10Aa.wav\n",
            " Processed 461/1440 audio samples 15a04Nc.wav\n",
            " Processed 462/1440 audio samples 14b09Wc.wav\n",
            " Processed 463/1440 audio samples 16b02Fd.wav\n",
            " Processed 464/1440 audio samples 15a04Wa.wav\n",
            " Processed 465/1440 audio samples 16a05Tb.wav\n",
            " Processed 466/1440 audio samples 15b10Nc.wav\n",
            " Processed 467/1440 audio samples 14b10Wc.wav\n",
            " Processed 468/1440 audio samples 16a04Tc.wav\n",
            " Processed 469/1440 audio samples 16b03Nb.wav\n",
            " Processed 470/1440 audio samples 16a04Wb.wav\n",
            " Processed 471/1440 audio samples 15a01La.wav\n",
            " Processed 472/1440 audio samples 16a07Td.wav\n",
            " Processed 473/1440 audio samples 15a02Ea.wav\n",
            " Processed 474/1440 audio samples 16b01Fa.wav\n",
            " Processed 475/1440 audio samples 16b09Lb.wav\n",
            " Processed 476/1440 audio samples 16a04Nc.wav\n",
            " Processed 477/1440 audio samples 15a02La.wav\n",
            " Processed 478/1440 audio samples 15a01Ea.wav\n",
            " Processed 479/1440 audio samples 16b09Fb.wav\n",
            " Processed 480/1440 audio samples 16a02Ec.wav\n",
            " Processed 481/1440 audio samples 16a01Wb.wav\n",
            " Processed 482/1440 audio samples 15a02Na.wav\n",
            " Processed 483/1440 audio samples 16b10Lb.wav\n",
            " Processed 484/1440 audio samples 16b01Eb.wav\n",
            " Processed 485/1440 audio samples 15a02Ta.wav\n",
            " Processed 486/1440 audio samples 15a04Fd.wav\n",
            " Processed 487/1440 audio samples 16b03La.wav\n",
            " Processed 488/1440 audio samples 15b02Wc.wav\n",
            " Processed 489/1440 audio samples 15a04Wb.wav\n",
            " Processed 490/1440 audio samples 15a07Fb.wav\n",
            " Processed 491/1440 audio samples 15b02Aa.wav\n",
            " Processed 492/1440 audio samples 15b09Fa.wav\n",
            " Processed 493/1440 audio samples 15b03Lc.wav\n",
            " Processed 494/1440 audio samples 16a02Wb.wav\n",
            " Processed 495/1440 audio samples 16a04Ab.wav\n",
            " Processed 496/1440 audio samples 15b01Lb.wav\n",
            " Processed 497/1440 audio samples 15b03Wb.wav\n",
            " Processed 498/1440 audio samples 15b02Nd.wav\n",
            " Processed 499/1440 audio samples 16b10Wb.wav\n",
            " Processed 500/1440 audio samples 14b10Tc.wav\n",
            " Processed 501/1440 audio samples 16a01Tb.wav\n",
            " Processed 502/1440 audio samples 15a04Ac.wav\n",
            " Processed 503/1440 audio samples 16a01Nc.wav\n",
            " Processed 504/1440 audio samples 16b03Ad.wav\n",
            " Processed 505/1440 audio samples 16b10Tb.wav\n",
            " Processed 506/1440 audio samples 15a05Lb.wav\n",
            " Processed 507/1440 audio samples 16b02Lb.wav\n",
            " Processed 508/1440 audio samples 15b09Wb.wav\n",
            " Processed 509/1440 audio samples 15a04Ab.wav\n",
            " Processed 510/1440 audio samples 16a05Wb.wav\n",
            " Processed 511/1440 audio samples 16a07Lb.wav\n",
            " Processed 512/1440 audio samples 16b03Fa.wav\n",
            " Processed 513/1440 audio samples 16b09La.wav\n",
            " Processed 514/1440 audio samples 14b10Nb.wav\n",
            " Processed 515/1440 audio samples 15b03Aa.wav\n",
            " Processed 516/1440 audio samples 16a04Ea.wav\n",
            " Processed 517/1440 audio samples 16b01Wb.wav\n",
            " Processed 518/1440 audio samples 14b10Lb.wav\n",
            " Processed 519/1440 audio samples 16b10Td.wav\n",
            " Processed 520/1440 audio samples 16a05Ab.wav\n",
            " Processed 521/1440 audio samples 14b09Lb.wav\n",
            " Processed 522/1440 audio samples 16a04Wc.wav\n",
            " Processed 523/1440 audio samples 16b09Ab.wav\n",
            " Processed 524/1440 audio samples 16a05Wc.wav\n",
            " Processed 525/1440 audio samples 15b02Wa.wav\n",
            " Processed 526/1440 audio samples 16b01Lc.wav\n",
            " Processed 527/1440 audio samples 14b09Td.wav\n",
            " Processed 528/1440 audio samples 15a05Eb.wav\n",
            " Processed 529/1440 audio samples 15b03Nb.wav\n",
            " Processed 530/1440 audio samples 16a05La.wav\n",
            " Processed 531/1440 audio samples 15b02Tc.wav\n",
            " Processed 532/1440 audio samples 16b01Aa.wav\n",
            " Processed 533/1440 audio samples 16b01Tb.wav\n",
            " Processed 534/1440 audio samples 16a07Wa.wav\n",
            " Processed 535/1440 audio samples "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RVUa7RAuL9hG"
      },
      "source": [
        "Let's see what the features we extracted look like, **also for saving both the features matrix as well as emotions array, we need to convert them to pandas dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mzxX583yL9hG",
        "outputId": "ef9e27cb-d2a0-4720-e2c5-be032ab9bd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audio samples represented: 1435\n",
            "Numerical features extracted per sample: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6    \\\n",
              "0    0.720641  0.720583  0.617265  0.595652  0.606965  0.608982  0.657078   \n",
              "1    0.564311  0.610758  0.603587  0.677393  0.742133  0.746390  0.661647   \n",
              "2    0.404909  0.515188  0.558104  0.571996  0.608146  0.599661  0.510465   \n",
              "3    0.512014  0.585578  0.589255  0.581887  0.606004  0.661837  0.657070   \n",
              "4    0.596133  0.637498  0.634938  0.684940  0.706530  0.701318  0.729132   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "530  0.490593  0.475538  0.487922  0.483907  0.528723  0.555341  0.560315   \n",
              "531  0.573591  0.600581  0.640882  0.625221  0.611145  0.606658  0.655966   \n",
              "532  0.501183  0.475831  0.568972  0.623233  0.633424  0.505099  0.461000   \n",
              "533  0.477399  0.481700  0.469323  0.447335  0.468794  0.591852  0.729825   \n",
              "534  0.548394  0.616139  0.657003  0.569550  0.448954  0.491863  0.597981   \n",
              "\n",
              "          7         8         9    ...       170       171        172  \\\n",
              "0    0.695031  0.698287  0.615263  ... -1.645359 -2.420688  -2.502800   \n",
              "1    0.631888  0.586567  0.574034  ...  3.288302  5.465301   4.083701   \n",
              "2    0.428739  0.506934  0.575784  ...  0.870254  1.566974   2.292184   \n",
              "3    0.611554  0.600824  0.648380  ...  0.134079  2.586298   3.310400   \n",
              "4    0.706555  0.696758  0.719856  ... -2.887378 -0.256546   0.757951   \n",
              "..        ...       ...       ...  ...       ...       ...        ...   \n",
              "530  0.547721  0.542872  0.608107  ...  1.602999  1.972751   1.122694   \n",
              "531  0.762373  0.764884  0.706915  ... -1.010411 -1.343182  -1.171554   \n",
              "532  0.511774  0.493369  0.450172  ...  1.194447 -2.293607  -4.348759   \n",
              "533  0.818915  0.744749  0.601236  ...  9.318092  6.190225  10.210866   \n",
              "534  0.627743  0.600697  0.532020  ...  3.998015  3.713844   0.759450   \n",
              "\n",
              "          173       174       175       176       177       178       179  \n",
              "0   -3.199017 -2.187031 -3.741765 -2.143440 -2.468618 -1.887268 -2.429971  \n",
              "1    7.782571  5.437661  4.327275  3.230336  4.754009  2.528432  1.852483  \n",
              "2    3.129890  1.996737  0.305314 -0.157051  3.427973  1.873118 -0.783700  \n",
              "3    3.682724  2.295565 -0.075023 -0.012579  3.551004  0.059484  3.154512  \n",
              "4   -1.229369 -2.373523 -0.323926 -2.219131 -1.226307 -0.720165 -2.720254  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "530  3.136306  1.353542  2.331070  1.019889  0.370863  1.585456  2.392996  \n",
              "531 -0.386646 -2.516057 -1.217895 -2.069217 -1.576747 -2.482699 -1.915226  \n",
              "532  1.462933 -4.639575 -0.469859  0.528223  2.264799 -0.020751  1.659330  \n",
              "533  8.599792  7.517327  3.568608  2.706643  0.351747 -1.561297  0.364550  \n",
              "534  1.963719 -1.669442 -1.020634 -1.388461  0.810363 -0.356627  0.859328  \n",
              "\n",
              "[535 rows x 180 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73744ef3-9e45-411b-a2a8-9a3cdca82c36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.720641</td>\n",
              "      <td>0.720583</td>\n",
              "      <td>0.617265</td>\n",
              "      <td>0.595652</td>\n",
              "      <td>0.606965</td>\n",
              "      <td>0.608982</td>\n",
              "      <td>0.657078</td>\n",
              "      <td>0.695031</td>\n",
              "      <td>0.698287</td>\n",
              "      <td>0.615263</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.645359</td>\n",
              "      <td>-2.420688</td>\n",
              "      <td>-2.502800</td>\n",
              "      <td>-3.199017</td>\n",
              "      <td>-2.187031</td>\n",
              "      <td>-3.741765</td>\n",
              "      <td>-2.143440</td>\n",
              "      <td>-2.468618</td>\n",
              "      <td>-1.887268</td>\n",
              "      <td>-2.429971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.564311</td>\n",
              "      <td>0.610758</td>\n",
              "      <td>0.603587</td>\n",
              "      <td>0.677393</td>\n",
              "      <td>0.742133</td>\n",
              "      <td>0.746390</td>\n",
              "      <td>0.661647</td>\n",
              "      <td>0.631888</td>\n",
              "      <td>0.586567</td>\n",
              "      <td>0.574034</td>\n",
              "      <td>...</td>\n",
              "      <td>3.288302</td>\n",
              "      <td>5.465301</td>\n",
              "      <td>4.083701</td>\n",
              "      <td>7.782571</td>\n",
              "      <td>5.437661</td>\n",
              "      <td>4.327275</td>\n",
              "      <td>3.230336</td>\n",
              "      <td>4.754009</td>\n",
              "      <td>2.528432</td>\n",
              "      <td>1.852483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.404909</td>\n",
              "      <td>0.515188</td>\n",
              "      <td>0.558104</td>\n",
              "      <td>0.571996</td>\n",
              "      <td>0.608146</td>\n",
              "      <td>0.599661</td>\n",
              "      <td>0.510465</td>\n",
              "      <td>0.428739</td>\n",
              "      <td>0.506934</td>\n",
              "      <td>0.575784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.870254</td>\n",
              "      <td>1.566974</td>\n",
              "      <td>2.292184</td>\n",
              "      <td>3.129890</td>\n",
              "      <td>1.996737</td>\n",
              "      <td>0.305314</td>\n",
              "      <td>-0.157051</td>\n",
              "      <td>3.427973</td>\n",
              "      <td>1.873118</td>\n",
              "      <td>-0.783700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.512014</td>\n",
              "      <td>0.585578</td>\n",
              "      <td>0.589255</td>\n",
              "      <td>0.581887</td>\n",
              "      <td>0.606004</td>\n",
              "      <td>0.661837</td>\n",
              "      <td>0.657070</td>\n",
              "      <td>0.611554</td>\n",
              "      <td>0.600824</td>\n",
              "      <td>0.648380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134079</td>\n",
              "      <td>2.586298</td>\n",
              "      <td>3.310400</td>\n",
              "      <td>3.682724</td>\n",
              "      <td>2.295565</td>\n",
              "      <td>-0.075023</td>\n",
              "      <td>-0.012579</td>\n",
              "      <td>3.551004</td>\n",
              "      <td>0.059484</td>\n",
              "      <td>3.154512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.596133</td>\n",
              "      <td>0.637498</td>\n",
              "      <td>0.634938</td>\n",
              "      <td>0.684940</td>\n",
              "      <td>0.706530</td>\n",
              "      <td>0.701318</td>\n",
              "      <td>0.729132</td>\n",
              "      <td>0.706555</td>\n",
              "      <td>0.696758</td>\n",
              "      <td>0.719856</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.887378</td>\n",
              "      <td>-0.256546</td>\n",
              "      <td>0.757951</td>\n",
              "      <td>-1.229369</td>\n",
              "      <td>-2.373523</td>\n",
              "      <td>-0.323926</td>\n",
              "      <td>-2.219131</td>\n",
              "      <td>-1.226307</td>\n",
              "      <td>-0.720165</td>\n",
              "      <td>-2.720254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>0.490593</td>\n",
              "      <td>0.475538</td>\n",
              "      <td>0.487922</td>\n",
              "      <td>0.483907</td>\n",
              "      <td>0.528723</td>\n",
              "      <td>0.555341</td>\n",
              "      <td>0.560315</td>\n",
              "      <td>0.547721</td>\n",
              "      <td>0.542872</td>\n",
              "      <td>0.608107</td>\n",
              "      <td>...</td>\n",
              "      <td>1.602999</td>\n",
              "      <td>1.972751</td>\n",
              "      <td>1.122694</td>\n",
              "      <td>3.136306</td>\n",
              "      <td>1.353542</td>\n",
              "      <td>2.331070</td>\n",
              "      <td>1.019889</td>\n",
              "      <td>0.370863</td>\n",
              "      <td>1.585456</td>\n",
              "      <td>2.392996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0.573591</td>\n",
              "      <td>0.600581</td>\n",
              "      <td>0.640882</td>\n",
              "      <td>0.625221</td>\n",
              "      <td>0.611145</td>\n",
              "      <td>0.606658</td>\n",
              "      <td>0.655966</td>\n",
              "      <td>0.762373</td>\n",
              "      <td>0.764884</td>\n",
              "      <td>0.706915</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.010411</td>\n",
              "      <td>-1.343182</td>\n",
              "      <td>-1.171554</td>\n",
              "      <td>-0.386646</td>\n",
              "      <td>-2.516057</td>\n",
              "      <td>-1.217895</td>\n",
              "      <td>-2.069217</td>\n",
              "      <td>-1.576747</td>\n",
              "      <td>-2.482699</td>\n",
              "      <td>-1.915226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>0.501183</td>\n",
              "      <td>0.475831</td>\n",
              "      <td>0.568972</td>\n",
              "      <td>0.623233</td>\n",
              "      <td>0.633424</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.461000</td>\n",
              "      <td>0.511774</td>\n",
              "      <td>0.493369</td>\n",
              "      <td>0.450172</td>\n",
              "      <td>...</td>\n",
              "      <td>1.194447</td>\n",
              "      <td>-2.293607</td>\n",
              "      <td>-4.348759</td>\n",
              "      <td>1.462933</td>\n",
              "      <td>-4.639575</td>\n",
              "      <td>-0.469859</td>\n",
              "      <td>0.528223</td>\n",
              "      <td>2.264799</td>\n",
              "      <td>-0.020751</td>\n",
              "      <td>1.659330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>0.477399</td>\n",
              "      <td>0.481700</td>\n",
              "      <td>0.469323</td>\n",
              "      <td>0.447335</td>\n",
              "      <td>0.468794</td>\n",
              "      <td>0.591852</td>\n",
              "      <td>0.729825</td>\n",
              "      <td>0.818915</td>\n",
              "      <td>0.744749</td>\n",
              "      <td>0.601236</td>\n",
              "      <td>...</td>\n",
              "      <td>9.318092</td>\n",
              "      <td>6.190225</td>\n",
              "      <td>10.210866</td>\n",
              "      <td>8.599792</td>\n",
              "      <td>7.517327</td>\n",
              "      <td>3.568608</td>\n",
              "      <td>2.706643</td>\n",
              "      <td>0.351747</td>\n",
              "      <td>-1.561297</td>\n",
              "      <td>0.364550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>0.548394</td>\n",
              "      <td>0.616139</td>\n",
              "      <td>0.657003</td>\n",
              "      <td>0.569550</td>\n",
              "      <td>0.448954</td>\n",
              "      <td>0.491863</td>\n",
              "      <td>0.597981</td>\n",
              "      <td>0.627743</td>\n",
              "      <td>0.600697</td>\n",
              "      <td>0.532020</td>\n",
              "      <td>...</td>\n",
              "      <td>3.998015</td>\n",
              "      <td>3.713844</td>\n",
              "      <td>0.759450</td>\n",
              "      <td>1.963719</td>\n",
              "      <td>-1.669442</td>\n",
              "      <td>-1.020634</td>\n",
              "      <td>-1.388461</td>\n",
              "      <td>0.810363</td>\n",
              "      <td>-0.356627</td>\n",
              "      <td>0.859328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>535 rows × 180 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73744ef3-9e45-411b-a2a8-9a3cdca82c36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73744ef3-9e45-411b-a2a8-9a3cdca82c36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73744ef3-9e45-411b-a2a8-9a3cdca82c36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1f520dd-13b9-4e99-af2f-de83d06b66db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1f520dd-13b9-4e99-af2f-de83d06b66db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1f520dd-13b9-4e99-af2f-de83d06b66db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f97a4f11-a999-4907-9e77-69b9d65751ad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f97a4f11-a999-4907-9e77-69b9d65751ad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "print(f'\\nAudio samples represented: {features.shape[0]}')\n",
        "\n",
        "print(f'Numerical features extracted per sample: {features.shape[1]}')\n",
        "features_df = pd.DataFrame(featuresEmo) # make it pretty for display\n",
        "\n",
        "\n",
        "#making dataframe for emotions as well\n",
        "emotions_df = pd.DataFrame(emotionsEmo) # make it pretty for display\n",
        "\n",
        "features_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge emodb with ravdess\n",
        "\n",
        "bothEmotions = np.append(emotionsEmo, emotions)\n",
        "bothFeatures = np.append(featuresEmo,features)\n",
        "\n"
      ],
      "metadata": {
        "id": "onLvIpGgPEUb"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Tq083zLEL9hH"
      },
      "source": [
        "We have a matrix of dim 1435 x 180. Looks good - 1435 audio samples, one per row, with a series of\n",
        "180 numerical features for each sample.\n",
        "\n",
        "**Each of the 1435 feature arrays has 180 features composed of 12 chromagram pitch classes + 128 mel spectrogram bands + 40 MFC coefficients.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will save our features matrix and emotions array in excel file we dont have to compute them everytime we run the notebook, we can just load them from the excel file whenever required. Make sure to change the path to according to your drive."
      ],
      "metadata": {
        "id": "VF2SggHTDqbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-saved Dataset"
      ],
      "metadata": {
        "id": "VpE5m-5aEyoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once saved you only need to load them later by running the cell below, and **skip every cell above** except for the one in which we import libraries."
      ],
      "metadata": {
        "id": "hHPB7dCqEotR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's see if they have been loaded correctly!"
      ],
      "metadata": {
        "id": "4x2dXjybD1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "id": "B5Xo1SVMD0qR",
        "outputId": "98300373-d0fd-4da6-eee2-60668cbc10a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  0.617466  0.576461  0.569040  0.609814  0.654684  0.701384  0.735561   \n",
              "1  0.623919  0.574488  0.517403  0.513132  0.550291  0.568414  0.568268   \n",
              "2  0.503092  0.500758  0.474714  0.501313  0.573869  0.604987  0.556901   \n",
              "3  0.677821  0.616982  0.615782  0.621085  0.626168  0.646080  0.691546   \n",
              "4  0.512131  0.457755  0.478713  0.520813  0.516800  0.540460  0.621741   \n",
              "\n",
              "        7         8         9    ...       170       171       172       173  \\\n",
              "0  0.717063  0.728129  0.702318  ... -3.581316 -0.467617 -3.222230  0.313375   \n",
              "1  0.579836  0.644346  0.689928  ...  1.126486  3.953426  1.156003  6.056956   \n",
              "2  0.569272  0.661844  0.735248  ... -1.041501  1.307965  0.363679  5.471038   \n",
              "3  0.685554  0.722938  0.696742  ... -1.149269  1.404988 -1.316433  3.550398   \n",
              "4  0.673709  0.763157  0.709443  ... -2.535597  1.397879 -0.517047  5.022032   \n",
              "\n",
              "        174       175        176       177       178       179  \n",
              "0  3.955157 -0.183977   1.367951  2.254531 -0.198084  4.343905  \n",
              "1  5.954752  3.322112   6.695466  4.928186  3.682733  4.037534  \n",
              "2  7.249944  8.715325  10.268682  9.382307  6.510154  2.336356  \n",
              "3  3.366586  0.352723   2.582228  2.148702  1.180273  4.521074  \n",
              "4  7.575803  4.056076   4.256593  3.530471  4.952089  5.641845  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2780b91d-3964-460f-93fa-d79a1285b178\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.617466</td>\n",
              "      <td>0.576461</td>\n",
              "      <td>0.569040</td>\n",
              "      <td>0.609814</td>\n",
              "      <td>0.654684</td>\n",
              "      <td>0.701384</td>\n",
              "      <td>0.735561</td>\n",
              "      <td>0.717063</td>\n",
              "      <td>0.728129</td>\n",
              "      <td>0.702318</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.581316</td>\n",
              "      <td>-0.467617</td>\n",
              "      <td>-3.222230</td>\n",
              "      <td>0.313375</td>\n",
              "      <td>3.955157</td>\n",
              "      <td>-0.183977</td>\n",
              "      <td>1.367951</td>\n",
              "      <td>2.254531</td>\n",
              "      <td>-0.198084</td>\n",
              "      <td>4.343905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.623919</td>\n",
              "      <td>0.574488</td>\n",
              "      <td>0.517403</td>\n",
              "      <td>0.513132</td>\n",
              "      <td>0.550291</td>\n",
              "      <td>0.568414</td>\n",
              "      <td>0.568268</td>\n",
              "      <td>0.579836</td>\n",
              "      <td>0.644346</td>\n",
              "      <td>0.689928</td>\n",
              "      <td>...</td>\n",
              "      <td>1.126486</td>\n",
              "      <td>3.953426</td>\n",
              "      <td>1.156003</td>\n",
              "      <td>6.056956</td>\n",
              "      <td>5.954752</td>\n",
              "      <td>3.322112</td>\n",
              "      <td>6.695466</td>\n",
              "      <td>4.928186</td>\n",
              "      <td>3.682733</td>\n",
              "      <td>4.037534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.503092</td>\n",
              "      <td>0.500758</td>\n",
              "      <td>0.474714</td>\n",
              "      <td>0.501313</td>\n",
              "      <td>0.573869</td>\n",
              "      <td>0.604987</td>\n",
              "      <td>0.556901</td>\n",
              "      <td>0.569272</td>\n",
              "      <td>0.661844</td>\n",
              "      <td>0.735248</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.041501</td>\n",
              "      <td>1.307965</td>\n",
              "      <td>0.363679</td>\n",
              "      <td>5.471038</td>\n",
              "      <td>7.249944</td>\n",
              "      <td>8.715325</td>\n",
              "      <td>10.268682</td>\n",
              "      <td>9.382307</td>\n",
              "      <td>6.510154</td>\n",
              "      <td>2.336356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.677821</td>\n",
              "      <td>0.616982</td>\n",
              "      <td>0.615782</td>\n",
              "      <td>0.621085</td>\n",
              "      <td>0.626168</td>\n",
              "      <td>0.646080</td>\n",
              "      <td>0.691546</td>\n",
              "      <td>0.685554</td>\n",
              "      <td>0.722938</td>\n",
              "      <td>0.696742</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.149269</td>\n",
              "      <td>1.404988</td>\n",
              "      <td>-1.316433</td>\n",
              "      <td>3.550398</td>\n",
              "      <td>3.366586</td>\n",
              "      <td>0.352723</td>\n",
              "      <td>2.582228</td>\n",
              "      <td>2.148702</td>\n",
              "      <td>1.180273</td>\n",
              "      <td>4.521074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.512131</td>\n",
              "      <td>0.457755</td>\n",
              "      <td>0.478713</td>\n",
              "      <td>0.520813</td>\n",
              "      <td>0.516800</td>\n",
              "      <td>0.540460</td>\n",
              "      <td>0.621741</td>\n",
              "      <td>0.673709</td>\n",
              "      <td>0.763157</td>\n",
              "      <td>0.709443</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.535597</td>\n",
              "      <td>1.397879</td>\n",
              "      <td>-0.517047</td>\n",
              "      <td>5.022032</td>\n",
              "      <td>7.575803</td>\n",
              "      <td>4.056076</td>\n",
              "      <td>4.256593</td>\n",
              "      <td>3.530471</td>\n",
              "      <td>4.952089</td>\n",
              "      <td>5.641845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 180 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2780b91d-3964-460f-93fa-d79a1285b178')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2780b91d-3964-460f-93fa-d79a1285b178 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2780b91d-3964-460f-93fa-d79a1285b178');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e30c9455-a536-4b19-8535-5d4120b92669\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e30c9455-a536-4b19-8535-5d4120b92669')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e30c9455-a536-4b19-8535-5d4120b92669 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esInVDq7L9hT"
      },
      "source": [
        "Let's see the class balance of our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Si3OFQe7L9hU",
        "outputId": "d3d13256-a15d-4345-cdfd-eb26c91f3957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The number of FixedLocator locations (8), usually from a call to set_ticks, does not match the number of labels (1).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-6e442677e1bd>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Emotion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 f\"for the old name will be dropped %(removal)s.\")\n\u001b[1;32m    296\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# wrapper() must keep the same documented signature as func(): if we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1970\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (8), usually from a call to set_ticks, does not match the number of labels (1)."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot emotions\n",
        "plt.figure(figsize=(35,4))\n",
        "plt.subplot(1,3,1)\n",
        "#np.unique returns ordered list of unique elements and count of each element\n",
        "emotion_list, count = np.unique(emotions, return_counts=True)\n",
        "plt.bar(x=range(8), height=count)\n",
        "\n",
        "plt.xticks(ticks=range(8), labels = [emotion for emotion in emotion_list],fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(35, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "\n",
        "# Assuming bothEmotions is now a list of strings representing emotions\n",
        "emotion_list, count = np.unique(bothEmotions, return_counts=True)\n",
        "plt.bar(x=range(len(emotion_list)), height=count)\n",
        "plt.xticks(ticks=range(len(emotion_list)), labels=emotion_list, fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ope2JvamWTFO",
        "outputId": "a3793b45-a997-4c43-c8f3-1f542dcf4362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'dict' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-5131634546b4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming bothEmotions is now a list of strings representing emotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memotion_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbothEmotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotion_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'str'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAFlCAYAAADMCx4cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZsElEQVR4nO3df2zV1f3H8Vdb6C1GWnBdb0t3tQPnT5RiK11BYlzubKKp44/FTgztGn9M7YxyswkVaEWUMr9KmkiViDr9Q1ecEWOkqbpOYtQuxEITnYDBou2Mt9A57mVFW+g93z+M19W2yKe8b3/g85HcPzg7n/s596S7z3zuL5Occ04AAJyi5PFeAADg9EBQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJjwH5a233lJpaalmzZqlpKQkvfzyy997zI4dO3TZZZfJ5/Pp3HPP1TPPPDOKpQIAJjLPQent7dW8efPU0NBwUvMPHDiga6+9VldddZXa29t199136+abb9Zrr73mebEAgIkr6VR+HDIpKUnbtm3TkiVLRpyzYsUKbd++XR988EF87De/+Y0OHz6s5ubm0Z4aADDBTEn0CVpbWxUMBgeNlZSU6O677x7xmL6+PvX19cX/HYvF9MUXX+hHP/qRkpKSErVUAPjBcM7pyJEjmjVrlpKTbd5OT3hQwuGw/H7/oDG/369oNKovv/xS06ZNG3JMXV2d1q5dm+ilAcAPXldXl37yk5+Y3FfCgzIa1dXVCoVC8X9HIhGdffbZ6urqUnp6+jiuDABOD9FoVIFAQNOnTze7z4QHJTs7W93d3YPGuru7lZ6ePuzViST5fD75fL4h4+np6QQFAAxZvo2Q8O+hFBcXq6WlZdDYG2+8oeLi4kSfGgAwhjwH5b///a/a29vV3t4u6euPBbe3t6uzs1PS1y9XlZeXx+ffdttt6ujo0D333KO9e/fqscce0wsvvKDly5fbPAIAwITgOSjvvfee5s+fr/nz50uSQqGQ5s+fr5qaGknS559/Ho+LJP30pz/V9u3b9cYbb2jevHl65JFH9OSTT6qkpMToIQAAJoJT+h7KWIlGo8rIyFAkEuE9FAAwkIjnVX7LCwBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACAiVEFpaGhQXl5eUpLS1NRUZF27tx5wvn19fU6//zzNW3aNAUCAS1fvlxfffXVqBYMAJiYPAdl69atCoVCqq2t1a5duzRv3jyVlJTo4MGDw85//vnntXLlStXW1mrPnj166qmntHXrVt17772nvHgAwMThOSgbN27ULbfcosrKSl100UXavHmzzjjjDD399NPDzn/33Xe1aNEiLV26VHl5ebr66qt1ww03fO9VDQBgcvEUlP7+frW1tSkYDH57B8nJCgaDam1tHfaYhQsXqq2tLR6Qjo4ONTU16ZprrhnxPH19fYpGo4NuAICJbYqXyT09PRoYGJDf7x807vf7tXfv3mGPWbp0qXp6enTFFVfIOafjx4/rtttuO+FLXnV1dVq7dq2XpQEAxlnCP+W1Y8cOrV+/Xo899ph27dqll156Sdu3b9e6detGPKa6ulqRSCR+6+rqSvQyAQCnyNMVSmZmplJSUtTd3T1ovLu7W9nZ2cMes2bNGi1btkw333yzJOmSSy5Rb2+vbr31Vq1atUrJyUOb5vP55PP5vCwNADDOPF2hpKamqqCgQC0tLfGxWCymlpYWFRcXD3vM0aNHh0QjJSVFkuSc87peAMAE5ekKRZJCoZAqKipUWFioBQsWqL6+Xr29vaqsrJQklZeXKzc3V3V1dZKk0tJSbdy4UfPnz1dRUZH279+vNWvWqLS0NB4WAMDk5zkoZWVlOnTokGpqahQOh5Wfn6/m5ub4G/WdnZ2DrkhWr16tpKQkrV69Wp999pl+/OMfq7S0VA8++KDdowAAjLskNwled4pGo8rIyFAkElF6evp4LwcAJr1EPK/yW14AABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBgYlRBaWhoUF5entLS0lRUVKSdO3eecP7hw4dVVVWlnJwc+Xw+nXfeeWpqahrVggEAE9MUrwds3bpVoVBImzdvVlFRkerr61VSUqJ9+/YpKytryPz+/n798pe/VFZWll588UXl5ubq008/1YwZMyzWDwCYIJKcc87LAUVFRbr88su1adMmSVIsFlMgENCdd96plStXDpm/efNm/d///Z/27t2rqVOnjmqR0WhUGRkZikQiSk9PH9V9AAC+lYjnVU8vefX396utrU3BYPDbO0hOVjAYVGtr67DHvPLKKyouLlZVVZX8fr/mzp2r9evXa2BgYMTz9PX1KRqNDroBACY2T0Hp6enRwMCA/H7/oHG/369wODzsMR0dHXrxxRc1MDCgpqYmrVmzRo888ogeeOCBEc9TV1enjIyM+C0QCHhZJgBgHCT8U16xWExZWVl64oknVFBQoLKyMq1atUqbN28e8Zjq6mpFIpH4raurK9HLBACcIk9vymdmZiolJUXd3d2Dxru7u5WdnT3sMTk5OZo6dapSUlLiYxdeeKHC4bD6+/uVmpo65Bifzyefz+dlaQCAcebpCiU1NVUFBQVqaWmJj8ViMbW0tKi4uHjYYxYtWqT9+/crFovFxz766CPl5OQMGxMAwOTk+SWvUCikLVu26Nlnn9WePXt0++23q7e3V5WVlZKk8vJyVVdXx+fffvvt+uKLL3TXXXfpo48+0vbt27V+/XpVVVXZPQoAwLjz/D2UsrIyHTp0SDU1NQqHw8rPz1dzc3P8jfrOzk4lJ3/bqUAgoNdee03Lly/XpZdeqtzcXN11111asWKF3aMAAIw7z99DGQ98DwUAbI3791AAABgJQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATowpKQ0OD8vLylJaWpqKiIu3cufOkjmtsbFRSUpKWLFkymtMCACYwz0HZunWrQqGQamtrtWvXLs2bN08lJSU6ePDgCY/75JNP9Ic//EGLFy8e9WIBABOX56Bs3LhRt9xyiyorK3XRRRdp8+bNOuOMM/T000+PeMzAwIBuvPFGrV27VrNnzz6lBQMAJiZPQenv71dbW5uCweC3d5CcrGAwqNbW1hGPu//++5WVlaWbbrrppM7T19enaDQ66AYAmNg8BaWnp0cDAwPy+/2Dxv1+v8Lh8LDHvP3223rqqae0ZcuWkz5PXV2dMjIy4rdAIOBlmQCAcZDQT3kdOXJEy5Yt05YtW5SZmXnSx1VXVysSicRvXV1dCVwlAMDCFC+TMzMzlZKSou7u7kHj3d3dys7OHjL/448/1ieffKLS0tL4WCwW+/rEU6Zo3759mjNnzpDjfD6ffD6fl6UBAMaZpyuU1NRUFRQUqKWlJT4Wi8XU0tKi4uLiIfMvuOACvf/++2pvb4/frrvuOl111VVqb2/npSwAOI14ukKRpFAopIqKChUWFmrBggWqr69Xb2+vKisrJUnl5eXKzc1VXV2d0tLSNHfu3EHHz5gxQ5KGjAMAJjfPQSkrK9OhQ4dUU1OjcDis/Px8NTc3x9+o7+zsVHIyX8AHgB+aJOecG+9FfJ9oNKqMjAxFIhGlp6eP93IAYNJLxPMqlxIAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBgYlRBaWhoUF5entLS0lRUVKSdO3eOOHfLli1avHixZs6cqZkzZyoYDJ5wPgBgcvIclK1btyoUCqm2tla7du3SvHnzVFJSooMHDw47f8eOHbrhhhv05ptvqrW1VYFAQFdffbU+++yzU148AGDiSHLOOS8HFBUV6fLLL9emTZskSbFYTIFAQHfeeadWrlz5vccPDAxo5syZ2rRpk8rLy0/qnNFoVBkZGYpEIkpPT/eyXADAMBLxvOrpCqW/v19tbW0KBoPf3kFysoLBoFpbW0/qPo4ePapjx47prLPO8rZSAMCENsXL5J6eHg0MDMjv9w8a9/v92rt370ndx4oVKzRr1qxBUfquvr4+9fX1xf8djUa9LBMAMA7G9FNeGzZsUGNjo7Zt26a0tLQR59XV1SkjIyN+CwQCY7hKAMBoeApKZmamUlJS1N3dPWi8u7tb2dnZJzz24Ycf1oYNG/T666/r0ksvPeHc6upqRSKR+K2rq8vLMgEA48BTUFJTU1VQUKCWlpb4WCwWU0tLi4qLi0c87qGHHtK6devU3NyswsLC7z2Pz+dTenr6oBsAYGLz9B6KJIVCIVVUVKiwsFALFixQfX29ent7VVlZKUkqLy9Xbm6u6urqJEl/+tOfVFNTo+eff155eXkKh8OSpDPPPFNnnnmm4UMBAIwnz0EpKyvToUOHVFNTo3A4rPz8fDU3N8ffqO/s7FRy8rcXPo8//rj6+/v161//etD91NbW6r777ju11QMAJgzP30MZD3wPBQBsjfv3UAAAGAlBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABMEBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgAmCAgAwQVAAACYICgDABEEBAJggKAAAEwQFAGCCoAAATBAUAIAJggIAMEFQAAAmCAoAwARBAQCYICgAABOjCkpDQ4Py8vKUlpamoqIi7dy584Tz//rXv+qCCy5QWlqaLrnkEjU1NY1qsQCAictzULZu3apQKKTa2lrt2rVL8+bNU0lJiQ4ePDjs/HfffVc33HCDbrrpJu3evVtLlizRkiVL9MEHH5zy4gEAE0eSc855OaCoqEiXX365Nm3aJEmKxWIKBAK68847tXLlyiHzy8rK1Nvbq1dffTU+9vOf/1z5+fnavHnzSZ0zGo0qIyNDkUhE6enpXpYLABhGIp5Xp3iZ3N/fr7a2NlVXV8fHkpOTFQwG1draOuwxra2tCoVCg8ZKSkr08ssvj3ievr4+9fX1xf8diUQkfb0BAIBT983zqcdrihPyFJSenh4NDAzI7/cPGvf7/dq7d++wx4TD4WHnh8PhEc9TV1entWvXDhkPBAJelgsA+B7//ve/lZGRYXJfnoIyVqqrqwdd1Rw+fFjnnHOOOjs7zR74ZBaNRhUIBNTV1cVLgGI/hsOeDMZ+DBWJRHT22WfrrLPOMrtPT0HJzMxUSkqKuru7B413d3crOzt72GOys7M9zZckn88nn883ZDwjI4M/hv+Rnp7OfvwP9mMo9mQw9mOo5GS7b494uqfU1FQVFBSopaUlPhaLxdTS0qLi4uJhjykuLh40X5LeeOONEecDACYnzy95hUIhVVRUqLCwUAsWLFB9fb16e3tVWVkpSSovL1dubq7q6uokSXfddZeuvPJKPfLII7r22mvV2Nio9957T0888YTtIwEAjCvPQSkrK9OhQ4dUU1OjcDis/Px8NTc3x9947+zsHHQJtXDhQj3//PNavXq17r33Xv3sZz/Tyy+/rLlz5570OX0+n2pra4d9GeyHiP0YjP0Yij0ZjP0YKhF74vl7KAAADIff8gIAmCAoAAATBAUAYIKgAABMTJig8JP4g3nZjy1btmjx4sWaOXOmZs6cqWAw+L37N9l4/fv4RmNjo5KSkrRkyZLELnAceN2Tw4cPq6qqSjk5OfL5fDrvvPNOq//feN2P+vp6nX/++Zo2bZoCgYCWL1+ur776aoxWm1hvvfWWSktLNWvWLCUlJZ3wtxO/sWPHDl122WXy+Xw699xz9cwzz3g/sZsAGhsbXWpqqnv66afdP//5T3fLLbe4GTNmuO7u7mHnv/POOy4lJcU99NBD7sMPP3SrV692U6dOde+///4YrzwxvO7H0qVLXUNDg9u9e7fbs2eP++1vf+syMjLcv/71rzFeeWJ43Y9vHDhwwOXm5rrFixe7X/3qV2Oz2DHidU/6+vpcYWGhu+aaa9zbb7/tDhw44Hbs2OHa29vHeOWJ4XU/nnvuOefz+dxzzz3nDhw44F577TWXk5Pjli9fPsYrT4ympia3atUq99JLLzlJbtu2bSec39HR4c444wwXCoXchx9+6B599FGXkpLimpubPZ13QgRlwYIFrqqqKv7vgYEBN2vWLFdXVzfs/Ouvv95de+21g8aKiorc7373u4Suc6x43Y/vOn78uJs+fbp79tlnE7XEMTWa/Th+/LhbuHChe/LJJ11FRcVpFxSve/L444+72bNnu/7+/rFa4pjyuh9VVVXuF7/4xaCxUCjkFi1alNB1joeTCco999zjLr744kFjZWVlrqSkxNO5xv0lr29+Ej8YDMbHTuYn8f93vvT1T+KPNH8yGc1+fNfRo0d17Ngx0x99Gy+j3Y/7779fWVlZuummm8ZimWNqNHvyyiuvqLi4WFVVVfL7/Zo7d67Wr1+vgYGBsVp2woxmPxYuXKi2trb4y2IdHR1qamrSNddcMyZrnmisnlPH/deGx+on8SeL0ezHd61YsUKzZs0a8gcyGY1mP95++2099dRTam9vH4MVjr3R7ElHR4f+/ve/68Ybb1RTU5P279+vO+64Q8eOHVNtbe1YLDthRrMfS5cuVU9Pj6644go553T8+HHddtttuvfee8diyRPOSM+p0WhUX375paZNm3ZS9zPuVyiwtWHDBjU2Nmrbtm1KS0sb7+WMuSNHjmjZsmXasmWLMjMzx3s5E0YsFlNWVpaeeOIJFRQUqKysTKtWrTrp/2rq6WbHjh1av369HnvsMe3atUsvvfSStm/frnXr1o330ia1cb9CGaufxJ8sRrMf33j44Ye1YcMG/e1vf9Oll16ayGWOGa/78fHHH+uTTz5RaWlpfCwWi0mSpkyZon379mnOnDmJXXSCjeZvJCcnR1OnTlVKSkp87MILL1Q4HFZ/f79SU1MTuuZEGs1+rFmzRsuWLdPNN98sSbrkkkvU29urW2+9VatWrTL9SffJYKTn1PT09JO+OpEmwBUKP4k/2Gj2Q5IeeughrVu3Ts3NzSosLByLpY4Jr/txwQUX6P3331d7e3v8dt111+mqq65Se3v7afFf/RzN38iiRYu0f//+eFwl6aOPPlJOTs6kjok0uv04evTokGh8E1v3A/x5Q7PnVG+fF0iMxsZG5/P53DPPPOM+/PBDd+utt7oZM2a4cDjsnHNu2bJlbuXKlfH577zzjpsyZYp7+OGH3Z49e1xtbe1p97FhL/uxYcMGl5qa6l588UX3+eefx29HjhwZr4dgyut+fNfp+Ckvr3vS2dnppk+f7n7/+9+7ffv2uVdffdVlZWW5Bx54YLwegimv+1FbW+umT5/u/vKXv7iOjg73+uuvuzlz5rjrr79+vB6CqSNHjrjdu3e73bt3O0lu48aNbvfu3e7TTz91zjm3cuVKt2zZsvj8bz42/Mc//tHt2bPHNTQ0TN6PDTvn3KOPPurOPvtsl5qa6hYsWOD+8Y9/xP+3K6+80lVUVAya/8ILL7jzzjvPpaamuosvvtht3759jFecWF7245xzznGShtxqa2vHfuEJ4vXv43+djkFxzvuevPvuu66oqMj5fD43e/Zs9+CDD7rjx4+P8aoTx8t+HDt2zN13331uzpw5Li0tzQUCAXfHHXe4//znP2O/8AR48803h31O+GYPKioq3JVXXjnkmPz8fJeamupmz57t/vznP3s+Lz9fDwAwMe7voQAATg8EBQBggqAAAEwQFACACYICADBBUAAAJggKAMAEQQEAmCAoAAATBAUAYIKgAABMEBQAgIn/BzNNGGHayAb/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_wKC8WL9hV"
      },
      "source": [
        "**Great, the classes appear to be balanced. That makes the task easier.** All emotions _except_ the neutral class have a \"strong\" intensity so there are half as many neutral samples. That might have an impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhtlYshOL9hV"
      },
      "source": [
        "### Feature Scaling\n",
        "To properly train most machine learning models on _most_ datasets, we first need to scale our features. **This is crucial for models which compute distances between data, and especially critical for DNNs**: If there is a difference in the variance of features simply because of their possible range of values, then a model will learn that the features with the greatest variance are the most important. However, **differences in the variance of unscaled features belonging to different and unknown distributions is an inappropriate measure of importance.** Let's check our features' properties:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_IUm1DLwL9hW",
        "outputId": "84bfe24a-06af-47a5-cae4-889efade71bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 Chromagram features:           min = 0.310,     max = 0.874,     mean = 0.666,     deviation = 0.085\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 149.208,     mean = 0.188,     deviation = 1.600\n",
            "\n",
            "40 MFCC features:                 min = -873.242,    max = 115.126,    mean = -14.626,    deviation = 98.494\n"
          ]
        }
      ],
      "source": [
        "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
        "def print_features(df):\n",
        "    # Check chromagram feature values\n",
        "    features_df_chromagram = df.loc[:,:11]\n",
        "    chroma_min = features_df_chromagram.min().min()\n",
        "    chroma_max = features_df_chromagram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    chroma_mean = features_df_chromagram.stack().mean()\n",
        "    chroma_stdev = features_df_chromagram.stack().std()\n",
        "    print(f'12 Chromagram features:       \\\n",
        "    min = {chroma_min:.3f}, \\\n",
        "    max = {chroma_max:.3f}, \\\n",
        "    mean = {chroma_mean:.3f}, \\\n",
        "    deviation = {chroma_stdev:.3f}')\n",
        "\n",
        "    # Check mel spectrogram feature values\n",
        "    features_df_melspectrogram = df.loc[:,12:139]\n",
        "    mel_min = features_df_melspectrogram.min().min()\n",
        "    mel_max = features_df_melspectrogram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mel_mean = features_df_melspectrogram.stack().mean()\n",
        "    mel_stdev = features_df_melspectrogram.stack().std()\n",
        "    print(f'\\n128 Mel Spectrogram features: \\\n",
        "    min = {mel_min:.3f}, \\\n",
        "    max = {mel_max:.3f}, \\\n",
        "    mean = {mel_mean:.3f}, \\\n",
        "    deviation = {mel_stdev:.3f}')\n",
        "\n",
        "    # Check MFCC feature values\n",
        "    features_df_mfcc = df.loc[:,140:179]\n",
        "    mfcc_min = features_df_mfcc.min().min()\n",
        "    mfcc_max = features_df_mfcc.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mfcc_mean = features_df_mfcc.stack().mean()\n",
        "    mfcc_stdev = features_df_mfcc.stack().std()\n",
        "    print(f'\\n40 MFCC features:             \\\n",
        "    min = {mfcc_min:.3f},\\\n",
        "    max = {mfcc_max:.3f},\\\n",
        "    mean = {mfcc_mean:.3f},\\\n",
        "    deviation = {mfcc_stdev:.3f}')\n",
        "\n",
        "print_features(features_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ha1FxBSCpqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFgQlYSlL9hW"
      },
      "source": [
        "**There's an obvious imbalance in the variance our features; Our features indeed belong to very different distributions:** our MFC coefficients' deviation is greater than the other features by orders of magnitude. That does not mean MFC coefficients are the most important feature, but rather it is a property of the way they are computed.  We will certainly need to scale this feature set.\n",
        "\n",
        "We have the choice of sklearn's StandardScaler and MinMaxScaler. Standard scaling subtracts the mean of each feature and divides it by the standard deviation of that feature, producing features with mean at zero and unit variance - that is, a variance and standard deviation of 1. Min-Max scaling transforms each feature to be within a bounded interval that we specify.\n",
        "\n",
        "In practice, **MinMax scaling is especially useful when we know our features should be in a bounded interval**, such as pixel values in [0,255], while **standard scaling is perhaps more practical for features with unknown distributions** because centering the features at zero-mean with a standard deviation of 1 means extreme values will have less of an impact on the model's learned weights, i.e. the model is less sensitive to outliers.\n",
        "\n",
        "We'll create MinMax scaled features as well so we can give them a try later on to confirm that standard scaling is better in the absence of knowledge on the appropriate distribution for a dataset's features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_BCAYVEUL9hW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_scaled = features\n",
        "features_scaled = scaler.fit_transform(features_scaled)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_minmax = features\n",
        "features_minmax = scaler.fit_transform(features_minmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ATx5oNL9hX"
      },
      "source": [
        "Make sure our features are properly scaled:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mlRuHQkKL9hX",
        "outputId": "d9f41781-976b-421f-d383-ad3e93297737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandard Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = -3.957,     max = 2.645,     mean = -0.000,     deviation = 1.000\n",
            "\n",
            "128 Mel Spectrogram features:     min = -0.475,     max = 36.480,     mean = 0.000,     deviation = 1.000\n",
            "\n",
            "40 MFCC features:                 min = -4.209,    max = 6.240,    mean = -0.000,    deviation = 1.000\n",
            "\n",
            "\n",
            "\u001b[1mMinMax Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.611,     deviation = 0.181\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.015,     deviation = 0.061\n",
            "\n",
            "40 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.406,    deviation = 0.166\n"
          ]
        }
      ],
      "source": [
        "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
        "features_scaled_df = pd.DataFrame(features_scaled)\n",
        "print_features(features_scaled_df)\n",
        "\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "features_minmax_df = pd.DataFrame(features_minmax)\n",
        "print_features(features_minmax_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZfzIh7DL9hX"
      },
      "source": [
        "Perfect. Zero mean and unit variance for standard scaling and in the range [0,1] for MinMax scaling - a default when we don't specify values. We can now move on to building predictive models for these features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5tXewLEL9hX"
      },
      "source": [
        "## Classical Machine Learning Models\n",
        "\n",
        "\n",
        "Classical machine learning models encompass a broad range of algorithms that have been foundational to the field's development and are still widely used for various predictive tasks. These models can be broadly categorized into supervised and unsupervised learning methods, each suited for different kinds of data and objectives.\n",
        "\n",
        "We will be looking into few popular Machine Learning Algorithms such as Support Vector Machine(SVM), K-Nearest Neighbors and Random Forest Classifier. There are many other classical models with their own strengths and weaknesses, and the choice of model depends on the specific requirements of the task, including the nature of the data, the complexity of the problem, and the computational efficiency required. Despite the rise of deep learning, classical machine learning models remain vital tools in a data scientist's arsenal due to their efficiency, interpretability, and strong performance in many scenarios.\n",
        "\n",
        "The use of classic machine learning method is due to the small size of our dataset; Some of the most robust models such as Support vector (machine) classifiers **(SVC) and k-Nearest-Neighbour classifiers (kNN) are particularly suited to smaller datasets and fall apart with huge datasets.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwU-jXSGL9hY"
      },
      "source": [
        "### Training: The 80/20 Split and Validation\n",
        "In order to compare models, we'll have to evaluate their performance. The simplest method to do so is to train a model on a portion of our dataset and test it on the remainder. We'll use sklearn's train_test_split to create a standard 80/20 train/test split. The model is fit on 80% of\n",
        "the data and tested for performance against 20% of the data, which it has never seen in training - also called the hold-out set.\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/Capture2.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "More accurately, the proper modality for training and scoring a model is to\n",
        "1. Fit/train our model on a _training_ set,\n",
        "2. Evaluate the model on a _validation_ set to tune the hyperparameters for better performance,\n",
        "3. Finally score our model's true performance - its **generalizability** - against a _test_ set, aka the hold-out set.\n",
        "4. Repeat from 2. **Do not tune the model to score well on the test set**.\n",
        "\n",
        "Different set ratios are used in this approach - a usual example is 60/20/20 train/validation/test.For simplicity, we're going to start with an 80/20 train/test split. The model will be trained on all the training data, and we will check its performance on the test data.\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/traintestsplit.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "Define unscaled and scaled training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8jGN4ROVL9hY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "############# Unscaled test/train set #############\n",
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "    features,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "############ Standard Scaled test/train set ###########\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_scaled, X_test_scaled, _, _ = train_test_split(\n",
        "    features_scaled,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "############# MinMax Scaled test/train set ###############\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_minmax, X_test_minmax, _, _ = train_test_split(\n",
        "    features_scaled,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=69\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Mh0RrEL9hY"
      },
      "source": [
        "### Comparing Models\n",
        "We'll try each off-the-shelf machine learning model from sklearn and pick a few to explore, since these models will train near instantly on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "scrolled": true,
        "id": "iLPeyR7vL9he",
        "outputId": "8ca42fac-5d3c-4b64-80d0-dbd3f8a5890d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Classifier Accuracy Score\n",
              "4         RandomForestClassifier         54.36%\n",
              "0           KNeighborsClassifier         54.01%\n",
              "1                            SVC         51.22%\n",
              "2                 SVC RBF kernel         44.25%\n",
              "3         DecisionTreeClassifier         32.75%\n",
              "6                     GaussianNB         28.92%\n",
              "5             AdaBoostClassifier         26.83%\n",
              "7  QuadraticDiscriminantAnalysis         23.34%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b50a5e6a-4068-42b4-a809-b317f646d0fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>54.36%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>54.01%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>51.22%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC RBF kernel</td>\n",
              "      <td>44.25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>32.75%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>28.92%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>26.83%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>23.34%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b50a5e6a-4068-42b4-a809-b317f646d0fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b50a5e6a-4068-42b4-a809-b317f646d0fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b50a5e6a-4068-42b4-a809-b317f646d0fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2873373-fc11-4faf-9c2b-1f61f68ae063\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2873373-fc11-4faf-9c2b-1f61f68ae063')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2873373-fc11-4faf-9c2b-1f61f68ae063 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classification_models = [\n",
        "    KNeighborsClassifier(),#(3),\n",
        "    SVC(kernel='linear'),#, C=0.025),\n",
        "    SVC(kernel='rbf'),\n",
        "    DecisionTreeClassifier(),#max_depth=5),\n",
        "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "scores = []\n",
        "for model in classification_models:\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    score = model.score(X_test_scaled, y_test)\n",
        "    model_name = type(model).__name__\n",
        "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
        "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
        "# Make it pretty\n",
        "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
        "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrD98CpPL9he"
      },
      "source": [
        "Let's pick the top three - Random Forests, SVC, and kNN - and take a closer look at each of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBNoEolL9hf"
      },
      "source": [
        "### The Support Vector Machine Classifier\n",
        "\n",
        "We'll go in chronological order. First is the support vector machine classifier (SVC) - a model from the 60s. SVMs are models quick to train for this task and best suited to small datasets due to its quadratic time complexity w.r.t. size of the training dataset (# of training samples). This is also the reason it breaks down with larger datasets since it becomes very expensive to train.\n",
        "\n",
        "The idea behind SVMs on which the SVC model is based is to find a separating hyperplane - a subspace with dimension one less than that of the feature space - for points in our feature space; i.e. for a 3D space, a hyperplane is a regular plane, in 2D, a line. This idea extends to n dimensions. If points are separable by a hyperplane, they are said to be linearly separable. **Since there are infinite possible separating hyperplanes for any linearly separable feature space, an SVM computes which points are closest to each such hyperplane and uses them to construct a _support vector_. The SVM picks the hyperplane which maximizes the distance - _margin_ - to each support vector.** In this way, we maximize the separating ability of the chosen hyperplane.\n",
        "\n",
        "The core of SVMs is the kernel. We could map all new points from our input space, where they were not separable by a hyperplane, to a higher dimension in which we have found a hyperplane to separate the points in that space. However, that would be extremely computationally expensive for data that needs to be mapped to much higher dimensions. Instead, we **compute the hyperplane in the higher dimension on our training data and map the hyperplane back to the lower-dimension input space to use for classifying our data. This is the _kernel trick_, whereby the kernel (function) enables us to compute distances to new points in the input space without transforming each to the higher dimensional space - drastically reducing the computational complexity of the SVM.**\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/kernel1.png?raw=true\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-VTE6HjL9hf"
      },
      "source": [
        "A linear kernel should always be tested because **a linear kernel is much faster to train than a non-linear kernel**; however, properly tuned, a non-linear kernel often provides the best possible predictive performance. **RBF (radial basis function) is a good default to use for a non-linear kernel** and often is the best non-linear kernel because it usually provides a higher accuracy compared to other non-linear kernels at the cost of higher computational complexity. We can afford to try the RBF kernel because our dataset is small.\n",
        "\n",
        "If you want to explore further please have a look at [this article](https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ruBbt50ML9hf",
        "outputId": "534dd63d-3fca-4783-91be-570d9b1a3d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Model's accuracy on training set is 100.00%\n",
            "SVC Model's accuracy on test set is 50.87%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(\n",
        "    C=10,  #higher the value tighter the margin\n",
        "    gamma='auto',\n",
        "    kernel='rbf',\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'SVC Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'SVC Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIm1a-tiL9hg"
      },
      "source": [
        "Not bad at all for the relatively simple SVC model. **Hyperparameter 𝐶 regulates the margin.** It might do well to optimize the SVC model further if we don't find a better one. As it stands, we are looking for considerably higher performance in this task.\n",
        "\n",
        "Check out [this link](https://towardsdatascience.com/visualizing-the-effect-of-hyperparameters-on-support-vector-machines-b9eef6f7357b) for visual representation of affect of changes in C and gamma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72LJRfCL9hg"
      },
      "source": [
        "### k Nearest Neighbours\n",
        "\n",
        "k Nearest Neighbours (kNN) is next in line, a tried-and-true machine learning method from the 70s. kNN makes a lot of intuitive sense: imagine plotting points on a graph and drawing gates around points that look like they belong to the same group. That's what it is - we **plot our training samples' features and compare a test sample's features' distance to all those points; then just take the _k_ closest points to the test sample and pick the most frequent label/class.** That's it.\n",
        "\n",
        "kNN is a great starting point for multiclass problems with small datasets, although on large dadtasets less reliable and extremely memory hungry (it stores all training sample points). kNN is also useful in that it makes **no assumptions about the underlying distribution of the data set - so kNNs work well for both linear and non-linear data.** In the 2D example:\n",
        "\n",
        "<img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/knn.png?raw=true\" width=400 height=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qaeCneMiL9hg",
        "outputId": "1864eb91-0479-48b1-b54d-e8f96430a496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default kNN Model's accuracy on training set is 67.77%\n",
            "Default kNN Model's accuracy on test set is 39.02%\n",
            "\n",
            "kNN Model's accuracy on training set is 100.00%\n",
            "kNN Model's accuracy on test set is 42.16%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "####### Default kNN  ########\n",
        "model = KNeighborsClassifier(\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Default kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "##### (hastily) tuned kNN ######\n",
        "model = KNeighborsClassifier(\n",
        "    n_neighbors = 5,\n",
        "    weights = 'distance',\n",
        "    algorithm = 'brute',\n",
        "    n_jobs=4\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxVEKUyiL9hh"
      },
      "source": [
        "**The brute-force algorithm computes distances between all pairs of points in the training set; works especially well for small datasets** but wildly inefficient w.r.t. increasing samples and feature space dimension. Not bad for 2 minutes of work, but still not suitable for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvQ3av4cL9hh"
      },
      "source": [
        "### Random Forests\n",
        "Finally, and before resorting to deep learning methods, let's try a Random Forest -  a model from the 21st century (2001). **We train many distinct decision trees which are essentially directed acyclic graphs (DAGs), somewhat similar to a flow chart. The collection of (decision) trees makes up our Random Forest.**\n",
        "\n",
        "At each node of the tree we have a function (a rule) that evaluates whether the features of samples input to that node belong to one class or another. Each branch of the tree (or, edge of the graph) defines one of two possible results from a node, and each leaf is one of two decisions made by its parent node. **Each tree in the forest evaluates a random subset of the training samples' features and has a rule at each level of the tree that classifies based on these random features - hence, _Random_ Forest. This random selection of features makes Random Forests robust to outliers**, as such features will have less of an impact in the scope of the entire forest, most of whose trees operate on the \"real\" features.\n",
        "\n",
        "**Random Forests are excellent models to use as a benchmark due to their low time complexity to train and because it is an ensemble method, their robustness to unknown distributions and outliers in the dataset,** meaning Random Forests require relatively little exploratory analysis in both the data and training the model to get an idea of their performance in a task.\n",
        "\n",
        "<img src=\"https://github.com/IliaZenkov/sklearn-audio-classification/blob/master/img/randomforest.png?raw=true\" width=500 height=500 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "j9BWmcV9L9hh",
        "outputId": "4df1efa5-abda-439b-c67e-0e35f3cd456c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Random Forest Model's accuracy on training set is 100.00%\n",
            "Default Random Forest Model's accuracy on test set is 53.66%\n",
            "\n",
            "Random Forest Model's accuracy on training set is 100.00%\n",
            "Random Forest Model's accuracy on test set is 56.79%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "####### Default Random Forest ########\n",
        "model = RandomForestClassifier(\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Default Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "\n",
        "########## Tuned Random Forest #######\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators = 500,\n",
        "    criterion ='entropy',\n",
        "    warm_start = True,\n",
        "    max_features = 'sqrt',\n",
        "    oob_score = True, # more on this below\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9-k8KLL9hi"
      },
      "source": [
        "Not bad for zero effort put into the default model. **Random Forests make a good benchmark model**, especially when strapped for time.\n",
        "\n",
        "**_Max features_ defines size of random feature subset decided upon at each node; sqrt(#features) is a good default for classification.**\n",
        "\n",
        "**_Gini_ and _Entropy_ are functions computing quality of classified samples within each node; they almost always provide similar performance but Entropy is more suited to classification while Gini is better for continuous variables.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnhnxuGXL9hi"
      },
      "source": [
        "\n",
        "As wonderful as Random Forests are, it's clear that we're going to need to pull out bigger guns if we want to get appreciable performance on this dataset, perhaps even with good generalizability on test data. DNNs(Deep Neural Networks) are the next step-up in complexity from classical machine learning models, and we will start at the first rung on that ladder:Simple Perceptron in next lab!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (Speech Classifier)",
      "language": "python",
      "name": "pycharm-6a34225"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}